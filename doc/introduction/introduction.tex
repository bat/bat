\documentclass[11pt, a4paper]{article}

%\usepackage{geometry}
%\usepackage{epsfig}
%\usepackage{epstopdf}
%\usepackage{graphics}
\usepackage{graphicx}
\usepackage{url}
\usepackage{parskip}

\setlength{\oddsidemargin}{0cm}
\setlength{\evensidemargin}{0cm}
\setlength{\topmargin}{-1cm}
\setlength{\textheight}{23cm}
\setlength{\textwidth}{16cm}

%\setlength{\parindent}{0pt}

\pagestyle{headings}

\newcommand{\bat}{{\sc BAT}}
\newcommand{\BAT}{\bat}
\newcommand{\Root}{{\sc Root}}
\newcommand{\versionno}{0.9}
\newcommand{\version}{version~\versionno}
\newcommand{\Version}{Version~\versionno}
\newcommand{\RootVersion}{5.22}
\newcommand{\RooStatsVersion}{5.27/04}
\newcommand{\CubaVersion}{2.0}

\newcommand{\code}[1]{\texttt{#1}}

%--------------------------------------------------------

\begin{document}

% --------------------------------------------------------
% title
% --------------------------------------------------------

\thispagestyle{empty}

\begin{figure}
\includegraphics[scale=0.25]{bat.eps}
\end{figure}

\vspace*{1cm}

\begin{center}


{\Large A short introduction to \bat}
\\

\vspace{1cm}

{\large \bat\ \version}

\end{center}

\thispagestyle{empty}

\vfill

\begin{center}
\today
\end{center}

\pagebreak

% --------------------------------------------------------
% table of contents
% --------------------------------------------------------

\thispagestyle{empty}

\enlargethispage{2cm}

\tableofcontents

\pagebreak

% --------------------------------------------------------
% introduction
% --------------------------------------------------------
\section{Introduction}
\label{section:introduction}

The Bayesian Analysis Toolkit, \bat, is a software package designed to
help solve statistical problems encountered in Bayesian
inference. Allowing to formulate models and their parameters, the main
purpose of the toolkit is to provide methods to solve the numerical
optimization and integration. It features the possibility to estimate
parameters and to compare models. A procedure to estimate the
goodness-of-fit is included and based on ensemble tests. A detailed
introduction to \bat\ can be found in~\cite{Caldwell:2008fw}.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% installation
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\section{Installation}
\label{section:installation}

\subsection{Availability}

\bat\ can be downloaded from \url{http://www.mppmu.mpg.de/bat}.

\bat\ is a free software: you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License (LGPL) as
published by the Free Software Foundation, either version 3 of
the License, or any later version.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Platforms}

\bat\ has been developed on Linux machines running different distributions
and different versions of the kernel and gcc. As far as we know there
is nothing distribution dependent inside of \bat. However, we have not
yet started to systematically check for compatibility and
portability. This is planned for future releases of \bat. For the
moment the only statement we can do here is that if you don't have a
too old or too specific installation of Linux you should be able to
compile and use \bat\ without problems.

The installation and functionality of BAT has also been tested on MACs.

Windows is not supported for the moment.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Dependencies}
% To save space in the contents, this particular subsubsection is not
% listed in the ToC. Comment out the \addtocontents commands to
% reverse this change.
\addtocontents{toc}{\protect\setcounter{tocdepth}{2}}
\subsubsection{\Root}
\addtocontents{toc}{\protect\setcounter{tocdepth}{3}}
\Root\ is an object oriented data analysis framework. You can obtain it
from~\cite{ROOTweb}. To compile and run \bat\ you will need a \Root\
version \RootVersion\ or later. Please, check your Linux distribution for the
availability of precompiled packages on your system. Mostly used
distributions nowadays have the \Root\ packages available.

Note: To be able to use the interface to RooFit/RooStats the \Root\
version \RooStatsVersion\ or later is necessary and \Root\ has to be compiled
with \verb|MathMore| support.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Recommendations}
% To save space in the contents, this particular subsubsection is not
% listed in the ToC. Comment out the \addtocontents commands to
% reverse this change.
\addtocontents{toc}{\protect\setcounter{tocdepth}{2}}
\subsubsection{Cuba}
\addtocontents{toc}{\protect\setcounter{tocdepth}{3}}
Cuba~\cite{CUBA} is a library containing general purpose
multidimensional integration algorithms. It can be obtained
from~\cite{CUBAweb}. BAT will compile and run with Cuba version
\CubaVersion\ or later. Cuba is not necessary to run BAT, however, its
use is recommended as it provides integration routines tuned for
performance, which are very usefull for integration in problems with
large number of dimensions.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Installation procedure}

Unpack the tarball containing the \bat\ source usually named like
\verb|BAT-x.x.tar.gz| (here x.x is the version number) using command
%
\begin{verbatim}
   tar -xzf BAT-x.x.tar.gz
\end{verbatim}
%
A directory called \verb|BAT-x.x| will be created containing the source code.
Enter the directory and run the configuration using commands
%
\begin{verbatim}
   cd BAT-x.x
   ./configure
\end{verbatim}

This will check your system for all components needed to compile \bat\
and set up the paths for installation. You can add option
\verb|--prefix=/path/to/install/bat| to \verb|./configure| to specify
the the prefix to the \bat\ installation path. The \bat\ library files
will be installed to \verb|$prefix/lib| and the include files to
\verb|$prefix/include|. Default installation prefix is
\verb|/usr/local|.

The configure script checks for \Root\ availability in the system and
fails if \Root\ is not installed. You can specify the ROOTSYS directory
using \verb|--rootsys=/path/to/rootsys|.

You can compile \BAT\ with the RooFit/RooStats support using
\verb|--with-roostats|. The configure script will check whether the version of
\Root\ is sufficient and whether it was compiled with RooFit/RooStats
support.

You can compile \BAT\ with Cuba support using option \verb|--with-cuba|.
The configure will then search for \verb|libcuba.a| and \verb|cuba.h| in
the system. They either have to be available in the standard system path
or you can specify the location using
\verb|--with-cuba-include-dir=/path/to/cuba/header|
and \verb|--with-cuba-include-dir=/path/to/cuba/lib|.

You can list all available options using
%
\begin{verbatim}
   ./configure --help
\end{verbatim}

\enlargethispage{-\baselineskip}

After successful configuration, run
%
\begin{verbatim}
   make
   make install
\end{verbatim}
%
to compile and install \bat. Note that depending on the setting of
installation prefix you might need root privileges to be able to
install \bat. If you are installing \bat\ e.g. in your
\verb|$HOMEDIR|, %$ workaround for bad highlighting you need to add
the path to the library and to the include files to the search path in
your system. Depending on your shell you can do that via commands
%
\begin{verbatim}
   export BATINSTALLDIR=/bat/install/prefix
   export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$BATINSTALLDIR/lib
   export CPATH=$CPATH:$BATINSTALLDIR/include
\end{verbatim}
%
or
%
\begin{verbatim}
   setenv BATINSTALLDIR    /bat/install/prefix
   setenv LD_LIBRARY_PATH  $LD_LIBRARY_PATH:$BATINSTALLDIR/lib
   setenv CPATH            $PATH:$BATINSTALLDIR/include
\end{verbatim}
%
for \verb|bash| and \verb|csh| compatible shells, respectively.

An option for use in compiled programs would also be to add
\verb|-I/bat/install/include/path| to \verb|CFLAGS| and
\verb|-L/bat/install/lib/path| to \verb|LDFLAGS| in your
\verb|Makefile|. However, the interactive \Root\ macros will not work if
\verb|libBAT.so|, \verb|libBATmodels.so|, \verb|libBAT.rootmap| and
\verb|libBATmodels.rootmap| aren't in the system library search path.

See also \verb|INSTALL| file in the \bat\ distribution for
installation instructions.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% analysis chain
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

%\pagebreak

\section{Running \bat}
\label{section:running}

\subsection{The analysis chain}
\label{subsection:chain}

The typical analysis chain in \bat\ is the following: one or several
models are defined together with their parameters and corresponding
ranges. Data is read in from a file and interfaced with each
model. For each model parameters are estimated either from the
posterior probability density or from the marginalized probability
densities of the individual parameters. Models can be compared using
direct probabilities or Bayes factors. A goodness--of--fit test can be
performed by evaluating the likelihood for an ensemble of possible
data sets given the best-fit parameters. The data sets are generated
under the assumption of the model at hand and the best-fit
parameters.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Getting started}
\label{subsection:start}

\bat\ comes in form of a library. It can be linked against in any
existing C++ code, or it can be used in an interactive
\Root\ session. The latter case is discussed later on in this
manual. Several files need to be provided by the user in order to
start a new project:
%
\begin{itemize}
\item A makefile in which the \bat\ library is linked.
\item Include and source files of the classes defining the models
used in the analysis (see next section).
\item A main file in which the actual analysis is performed.
\end{itemize}
%
The script \verb|BAT/tools/CreateProject.sh| can be used to create an
empty analysis skeleton including the above listed files. This is a
good starting point.

The script can take up to two parameters. The first parameter is the
name of the project, the second one is the name of new model class. If
only the name of the project is specified, only a Makefile and a main
C++ file are provided. This can be useful if predefined classes are
used in an analysis (see, e.g., the fast fitter classes described
later in this manual). If also a model class name is given, a C++
include and source file are created. These can be modified to the need
of user.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Creating a model}
\label{subsection:model}

% --------------------------------------------------------

\subsubsection{Implementation of a mathematical model as a C++ class}
\label{subsubsection:implementation}

The mathematical models used in \bat\ are implemented in terms of C++
classes. All model classes inherit from the pure-virtual base class
\verb|BCModel|, which has one member function that must be overloaded:
%
\begin{verbatim}
double BCModel::LogLikelihood(const std::vector <double> &params)
\end{verbatim}
%
This function calculates the conditional probability of the data given
a set of parameter values, $p(x|\vec{\lambda})$. It returns the
logarithm of the conditional probability for reasons of numerical
stability.
%

The member function
%
\begin{verbatim}
double BCModel::LogAPrioriProbability(const std::vector <double> &parameters)
\end{verbatim}
%
may also be overrided. It calculates the {\it a priori} probability
for a set of parameter values. It returns the logarithm of the
conditional probability for reasons of numerical stability. If the
{\it a priori} probablity is separable in terms of the individual
parameters, then this function need not be overloaded.  In this case,
the prior can be set for individual parameters through \Root\
\verb|TF1| objects (functions) with\footnote{\code{BCModel} also
  contains versions of all prior-setting functions that allow for
  reference to parameters by name rather than index.}
%
\begin{verbatim}
int BCModel::SetPrior(int index, TF1 * f).
\end{verbatim}
%
Three frequently used priors are predefined:
%
\begin{itemize}
\item \code{int SetPriorGauss(int index, double mean, double sigma)}\\
  A Gaussian prior.

\item \code{int SetPriorGauss(int index, double mean, double sigmadown, double sigmaup)}\\
  A Gaussian prior with upper and lower widths.

\item \code{int SetPriorDelta(int index, double value)}\\
  A delta-function prior; the parameter range is also set to the
  specified value.
\end{itemize}

Additionally, priors may be set from \Root\ \code{TH1} objects (1D
histograms) with
\begin{verbatim}
int SetPrior(int index, TH1 * h, bool flag=false).
\end{verbatim}
%

The prior may also be chosen constant with respect to individual
parameters or all of them with
%
\begin{verbatim}
int SetPriorConstant(int index)
int SetPriorConstantAll();
\end{verbatim}
%
The constant is calculated from the parameter ranges only once and
cached for reuse during the Markov chain run. For simple problems,
caching can significantly speed up execution, while for complicated
likelihoods, the time spent calculating the prior probability is
usually negligible.

Whenever a prior is undefined, \bat\ assumes a constant prior and
issues a warning.

% --------------------------------------------------------

\subsubsection{Definition of parameters of a model}
\label{subsubsection:parameters}

The parameters of a model are implemented as a C++ class named
\verb|BCModelParameter|. They can be added to a model in two ways:
Parameters can be defined explicitly and then added to a model via
%
\begin{verbatim}
BCParameter * parameter = new BCParameter(const char* name,
                                          double lowerlimit, double upperlimit);
int BCModel::AddParameter(BCParameter * parameter),
\end{verbatim}
%
where the arguments in the \code{BCParameter} constructor are the
name, lower limit, and upper limit of the parameter. Parameters can
also be defined implicitly via
%
\begin{verbatim}
int BCModel::AddParameter(const char* name, double lowerlimit, double upperlimit) .
\end{verbatim}

Each parameter must have a unique name and valid limits. Once added to
a model, each parameter is given a unique index starting at zero. A
parameter can be referenced by its index or by its name. It can be
returned from a model using the methods
%
\begin{verbatim}
BCParameter * BCModel::GetParameter(int index),
BCParameter * BCModel::GetParameter(char* name).
\end{verbatim}

It is possible to change the lower and upper limits of a parameter
after it has been added to the model:
%
\begin{verbatim}
int BCModel::SetParameterRange(int index, double parmin, double parmax) .
\end{verbatim}
%
A call to this method resets all results obtained so far since the
model has changed.

% --------------------------------------------------------

\subsubsection{A skeleton created by the CreateProject.sh script}
\label{subsubsection:createproject}

If the \verb|CreateProject.sh| script is called with two parameters,
C++ include and source files are created. One example is

\begin{verbatim}
./CreateProject.sh MyProject MyModel
--------------------------------------------------------------------------
The new BAT project was created in the directory 'MyProject'.
To test the configuration try to compile the project by running 'make'
inside the directory. In case there are some compilation errors you need
to adjust the parameters inside the 'Makefile'.

Once the program is compiled successfully, you can run it and it should
print some basic information on the screen.

Implement your model in file:    MyModel.cxx
Implement your analysis in file: runMyProject.cxx

Consult BAT webpage for details: http://www.mppmu.mpg.de/bat
--------------------------------------------------------------------------
\end{verbatim}

The include file will look like this
%
\begin{verbatim}
// ***************************************************************
// This file was created using the ./CreateProject.sh script
// for project MyProject
// ./CreateProject.sh is part of Bayesian Analysis Toolkit (BAT).
// BAT can be downloaded from http://www.mppmu.mpg.de/bat
// ***************************************************************

#ifndef __MYMODEL__H
#define __MYMODEL__H

#include <BAT/BCModel.h>

// This is a MyModel header file.
// Model source code is located in file MyProject/MyModel.cxx

// ---------------------------------------------------------
class MyModel : public BCModel
{
	public:

		// Constructors and destructor
		MyModel();
		MyModel(const char * name);
		~MyModel();

		// Methods to overload, see file MyModel.cxx
		void DefineParameters();
		double LogAPrioriProbability(const std::vector <double> &parameters);
		double LogLikelihood(const std::vector <double> &parameters);
    // void MCMCIterationInterface(); 
};
// ---------------------------------------------------------

#endif
\end{verbatim}

The constructors and the destructor are defined as well as the key
methods that define the likelihood and prior. The source file looks
like this
%
\begin{verbatim}
// ***************************************************************
// This file was created using the ./CreateProject.sh script
// for project MyProject
// ./CreateProject.sh is part of Bayesian Analysis Toolkit (BAT).
// BAT can be downloaded from http://www.mppmu.mpg.de/bat
// ***************************************************************

#include "MyModel.h"

#include <BAT/BCMath.h>

// ---------------------------------------------------------
MyModel::MyModel() : BCModel()
{  
	// default constructor
	DefineParameters();
};

// ---------------------------------------------------------
MyModel::MyModel(const char * name) : BCModel(name)
{ 
	// constructor
	DefineParameters();
};

// ---------------------------------------------------------
MyModel::~MyModel()
{
	// default destructor
};

// ---------------------------------------------------------
void MyModel::DefineParameters()
{
	// Add parameters to your model here.
	// You can then use them in the methods below by calling the
	// parameters.at(i) or parameters[i], where i is the index
	// of the parameter. The indices increase from 0 according to the
	// order of adding the parameters.

//	AddParameter("x", -10.0, 10.0); // index 0
//	AddParameter("y",  -5.0,  5.0); // index 1
}

// ---------------------------------------------------------
double MyModel::LogLikelihood(const std::vector <double> &parameters)
{
	// This methods returns the logarithm of the conditional probability
	// p(data|parameters). This is where you have to define your model.

	double logprob = 0.;

//	double x = parameters.at(0);
//	double y = parameters.at(1);
//	double eps = 0.5;

	// Breit-Wigner distribution of x with nuisance parameter y
//	logprob += BCMath::LogBreitWignerNonRel(x + eps*y, 0.0, 1.0);


	return logprob;
}

// ---------------------------------------------------------
double MyModel::LogAPrioriProbability(const std::vector <double> &parameters)
{
	// This method returns the logarithm of the prior probability for the
	// parameters p(parameters).

	double logprob = 0.;

//	double x = parameters.at(0);
//	double y = parameters.at(1);

//	double dx = GetParameter(0)->GetRangeWidth(); 

//	logprob += log(1./dx);                    // flat prior for x
//	logprob += BCMath::LogGaus(y, 0., 1.0);   // Gaussian prior for y

	return logprob;
}
// ---------------------------------------------------------
\end{verbatim}

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Data}
\label{subsection:data}

\subsubsection{Data format and handling}
\label{subsection:dataformat}

Data are managed in the form of data points that are combined to data
sets. Data points and sets are implemented as classes
\verb|BCDataPoint| and \verb|BCDataSet|.

The class \verb|BCDataPoint| contains a set of double precision
values. Data points can be generated explicitly by the user with or
without initial values with the constructors
%
\begin{verbatim}
BCDataPoint::BCDataPoint(int nvariables),
BCDataPoint::BCDataPoint(vector<double> x).
\end{verbatim}

Values of a data point can be set either one-by-one or all at once
with
%
\begin{verbatim}
void BCDataPoint::SetValue(int index, double value),
void BCDataPoint::SetValues(std::vector <double> values).
\end{verbatim}

The value of the $i$th entry can be recalled with
%
\begin{verbatim}
double BCDataPoint::GetValue(int index).
\end{verbatim}

A data point can be added to a data set with
%
\begin{verbatim}
void BCDataSet::AddDataPoint(BCDataPoint* datapoint).
\end{verbatim}

Alternatively, data can be read in from a file
%
\begin{itemize}
\item
  \verb|int BCDataSet::ReadDataFromFile(char* filename,|\\
  \verb|                                char* treename, const char* branchnames)|\\
  Data points are read from a \Root\ tree according to the
  comma-separated branch names in \code{branchnames}.

\item \code{int BCDataSet::ReadDataFromFile(char* filename, int nvariables)}\\
  Data points are read from an ASCII file containing one data point
  per line; each data point contains \code{nvariables} values.
\end{itemize}

Once a data set is defined it can be assigned to a model with
%
\begin{verbatim}
void BCModel::SetDataSet(BCDataSet* dataset).
\end{verbatim}

Similarly, a data set can be returned from a model with
%
\begin{verbatim}
BCDataSet * BCModel::GetDataSet().
\end{verbatim}

Though one can define several data sets, a model can only have one
data set at a time. This data set can be accessed in the overloaded
method \verb|BCModel::LogLikelihood|.

% --------------------------------------------------------

\subsubsection{Constraining the values of data points}

For two applications discussed later in this section---the
goodness-of-fit test and the calculation of error bands---it is
necessary to define the limits of the data points. This is done for
each variable separately. The limits are defined by the model, not by
the data set:
%
\begin{verbatim}
void BCModel::SetDataBoundaries(int index, double lowerboundary,
      													double upperboundary, bool fixed=false).
\end{verbatim}

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Managing more than one model: the model manager}
\label{subsection:modelmanager}

In case more than one model is defined and all models use the same
data set a model manager can be defined. It is implemented as a class
named \verb|BCModelManager|. Models and their prior probabilities are
added to the model manager via
%
\begin{verbatim}
void BCModelManager::AddModel(BCModel * model, double probability=0.),
\end{verbatim}
%
where \verb|probability| is the prior probability for the
model\footnote{Here the prior probability is for the model itself and
  is not to be confused with the intra-model parameter-dependent prior
  probabilities discussed in
  section~\ref{subsubsection:implementation}.}. A common data set can
be defined and will be used by all models added to the manager. This
can be done either explicitly via
%
\begin{verbatim}
void BCModelManager::SetDataSet(BCDataSet * dataset),
\end{verbatim}
%
or by reading data from a file via
%
\begin{verbatim}
int BCModelManager::ReadDataFromFile(char* filename, char* treename,
		    														 const char* branchnames),
int BCModelManager::ReadDataFromFile(char* filename, int nvariables).
\end{verbatim}

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Normalization and numerical integration}
\label{section:normalization}

The posterior probability density function (pdf) is normalized to
unity in Bayes' theorem. The normalization is an integral of the
conditional probability times the prior probability over the whole
parameter range. Since the analytical form of the integral is not
known in general this integral is solved numerically. \code{BCModel}
inherits from \code{BCIntegrate}, which contains several methods for
numerical integration. An integration method can be chosen by
%
\begin{verbatim}
void BCIntegrate::SetIntegrationMethod(BCIntegrate::BCIntegrationMethod method),
\end{verbatim}

where \verb|BCIntegrationMethod| can be one of the following
%
\begin{itemize}
\item \verb|BCModel::kIntMonteCarlo|. A sampled mean integration.
\item \verb|BCModel::kIntImportance|. A sampled mean integration
 with importance sampling.
\item \verb|BCModel::kIntMetropolis|. A sampled mean integration
 with importance sampling using Markov chains.
\item \verb|BCModel::kIntCuba|. An interface to the CUBA
  library~\cite{CUBA,CUBAweb}.
\end{itemize}
%

The normalization can be performed for each model separately or for
all models belonging to a model manager:
%
\begin{verbatim}
double BCModel::Normalize(),
void BCModelManager::Normalize().
\end{verbatim}
%
The normalization is stored for each model. The value can be obtained
by
%
\begin{verbatim}
double BCModel::GetNormalization() .
\end{verbatim}

Once the integral is calculated the posterior pdf for a set of
parameter values can be evaluated
%
\begin{verbatim}
double BCModel::Probability(const std::vector <double> &parameter),
double BCModel::LogProbability(const std::vector <double> &parameter),
\end{verbatim}
%
where the latter returns the logarithm of the posterior pdf.

\subsubsection{Cuba interface}
\label{section:cubainterface}

Cuba library contains four different integration algorithms. In \BAT\
one can choose the method using
%
\begin{verbatim}
void BCIntegrate::SetCubaIntegrationMethod(BCIntegrate::BCCubaMethod method)
\end{verbatim}
%
where \verb|BCCubaMethod| can be either \verb|kCubaVegas| (default)
or \verb|kCubaSuave|. The interface to the other two integration
algorithms (Divonne and Cuhre) will be implemented in the future.

One can tune the main parameters of Cuba using the following methods:
%
\begin{verbatim}
void SetCubaMinEval(int n)
void SetCubaMaxEval(int n)
void SetCubaVerbosityLevel(int level)
void SetCubaVegasNStart(int n)
void SetCubaVegasNIncrease(int n)
void SetCubaSuaveNNew(int n)
void SetCubaSuaveFlatness(double p)
\end{verbatim}
%
See the Cuba manual for details.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Parameter estimation and marginalization}

The posterior pdf can be used to estimate the set of parameter values
most suited to describe the data. This is done by searching for the
most probable value, or mode, of the posterior pdf. Two approaches are
followed: either the mode in the whole parameter space is searched
for, or the pdf is marginalized with respect to the particular
parameter under study. In the latter case, several quantities can used
to describe the marginalized distributions.

% --------------------------------------------------------

\subsubsection{Maximization of the full posterior probability density}

The maximization of the full posterior pdf can be performed using the
method
%
\begin{verbatim}
void BCModel::FindMode(std::vector<double> start = std::vector<double>(0)).
\end{verbatim}

The vector of parameter values which maximizes the posterior pdf can be obtained using
%
\begin{verbatim}
std::vector <double> BCModel::GetBestFitParameters(),
double BCModel::GetBestFitParameter(unsigned int index).
\end{verbatim}
%
The implemented algorithms can be chosen with the command
%
\begin{verbatim}
BCIntegrate::SetOptimizationMethod(BCIntegrate::BCOptimizationMethod method).
\end{verbatim}
%
Three methods are available in the current version (\Version):
%
\begin{itemize}
\item \verb|BCIntegrate::kOptMetropolis|. A sampling algorithm using the
  Metropolis algorithm.
\item \verb|BCIntegrate::kOptMinuit|. An interface to the \Root\ version
  of Minuit.
\item \verb|BCIntegrate::kOptSA|. A Simulated Annealing algorithm.
\end{itemize}
%
If the interface to Minuit is used, the estimated uncertainties on the
parameters can be obtained using
%
\begin{verbatim}
std::vector <double> BCModel::GetBestFitParameterErrors(),
double BCModel::GetBestFitParameterError(unsigned int index).
\end{verbatim}
%
Settings and options of the Simulated Annealing algorithm are
summarized in section~\ref{section:settings:SA}.

If several algorithms are ran one after the other, a flag controls
whether to ignore the results from a previous optimization:
%
\begin{verbatim}
void BCIntegrate::SetFlagIgnorePrevOptimization(bool flag).
\end{verbatim}

% --------------------------------------------------------

\subsubsection{Marginalization}
\label{subsubsection:marginalization}

The single parameter estimation is done via marginalization. If more
than one parameter is studied it is most efficient to marginalize with
respect to all parameters simultaneously. This can be done using
%
\begin{verbatim}
int BCModel::MarginalizeAll() .
\end{verbatim}
%
One- and two-dimensional histograms are filled during the
marginalization. They can be accessed by\footnote{In the following,
  functions with \code{BCParameter} arguments exist also as versions
  taking a parameter name as an argument instead.}
%
\begin{verbatim}
BCH1D * BCModel::GetMarginalized(BCParameter * parameter),
BCH2D * BCModel::GetMarginalized(BCParameter * parameter1,
                                 BCParameter * parameter2),
\end{verbatim}

Alternatively, the marginalization can be done for one or two
parameters individually:
%
\begin{verbatim}
TH1D * BCModel::Marginalize(BCParameter* parameter),
TH2D * BCModel::Marginalize(BCParameter * parameter1, BCParameter * parameter2),
\end{verbatim}

Different methods of marginalization are implemented and can be chosen
via
%
\begin{verbatim}
void BCIntegrate::SetMarginalizationMethod(BCIntegrate::BCMarginalizationMethod method)
\end{verbatim}

where \verb|BCMarginalizationMethod| can be one of the following
%
\begin{itemize}
\item \verb|BCIntegrate::kMargMonteCarlo|. Uncorrelated Monte Carlo sampling.
\item \verb|BCIntegrate::kMargMetropolis|. Correlated sampling using
  Markov Chain Monte Carlo (Metropolis algorithm).
\end{itemize}

Note that only Markov chains can be used if the marginalization is
done for all parameters simultaneously. Settings and options of the
Markov Chain Monte Carlo algorithm are summarized in
section~\ref{section:settings:MCMC}.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Model comparison and hypothesis testing}

% --------------------------------------------------------

\subsubsection{Model comparison}

Models $M_{i}$ can be compared by their posterior
probability. Technically, the models are added to a model manager and
given a prior probability (see
Section~\ref{subsection:modelmanager}). The posterior probability for
the $i$th model, given the data, is simply
%
\begin{equation}
p(\mathrm{M_{i}}|\mathrm{data}) = \frac{N_{\mathrm{i}} \cdot p_{0}(\mathrm{M_{i}})}{\sum_{\mathrm{j} = 1}^{N} N_{\mathrm{j}} \cdot p_{0}(\mathrm{M_{j}})} \, ,
\end{equation}
%
where $N_{i}$ is the normalization of the $i$th model posterior pdf
and $p_{0}(M_{i})$ is the prior probability for the $i$th model. The
posterior probability for a model can be evaluated once the model
manager is initialized and all numerical integrations are performed
via
%
\begin{verbatim}
void BCModelManager::Normalize().
\end{verbatim}
%
The posterior probability can be returned from the model using the
following method:
%
\begin{verbatim}
double BCModel::GetModelAPosterioriProbability().
\end{verbatim}

Alternatively, Bayes factors can be calculated for two models using
%
\begin{verbatim}
double BCModelManager::BayesFactor(const unsigned int imodel1,
                                   const unsigned int imodel2),
\end{verbatim}
%
where the arguments are the indices of the models in the model
manager.


% --------------------------------------------------------

\subsubsection{Goodness-of-fit test}

Once the most suitable set of parameters, $\vec{\lambda}^{*}$, for a
given model and data set, $D$, is estimated it is necessary
to verify that the one  model under consideration
gives a reasonable representation of the data
(regardless of any alternative models). To this end, one can
define a test statistic and calculate a $p$-value. Many more
details on the interpretation of $p$-values and the various
choices of test statistics for common fitting problems can be found
in \cite{BAT_pValue}.

For the most general model, this is accomplished as follows.
Data sets, $\{ \tilde{D} \}$, are generated under the
assumption of the model and the best-fit-parameters. A frequency
distribution $f$ of the obtained conditional probability
$k=p(\tilde{D}|\vec{\lambda}^{*})$ is calculated and interpreted as
probability density. $k$ is used as the test statistic.
The $p$-value is defined as the probability to
find a conditional probability $p(\tilde{D}|\vec{\lambda}^{*})$ equal
or less than that found for the original data set,
$k_{0}=p(D|\vec{\lambda}^{*})$, i.e.
%
\begin{equation}
p \equiv  \int_{0}^{k_{0}=p(D|\vec{\lambda}^{*})} f(k) \, \mathrm{d}k \, .
\end{equation}

In the most general case, the $p$-value is calculated using Markov
Chain Monte Carlo. The dimension of the sampled space is the number
of datapoints.
 The calculation can be started by
%
\begin{verbatim}
BCH1D * BCModel::CalculatePValue(std::vector<double> par,
                                 bool flag_histogram=false),
\end{verbatim}
%
where \verb|par| is a vector of the best-fit-parameters. The method
returns a pointer to a \verb|BCH1D| if the flag is set to true. The
$p$-value is calculated from this distribution and can be obtained by
%
\begin{verbatim}
double BCModel::GetPValue().
\end{verbatim}

For a number of models the distribution of test certain statistics is
approximately known. Hence the CPU intensive generation of data sets
can be avoided, and the $p$-value is computed much faster.

If the total probability of the data $p\left(D|\vec{\lambda}^{*}\right)$
 factorizes into $N$ independent observations
$$p\left(D|\vec{\lambda}^{*}\right) = \prod_{i=1}^N
p_i\left(y_i|\vec{\lambda}^{*}\right)$$ and the cumulative
distribution functions (CDF) $F_i(y)= \int_{-\infty}^{y}
p_i(y'|\vec{\lambda}^{*}) \mathrm{d }y'$ are known, the $\chi^2$ test
statistic described by Johnson \cite{Johnson_pValue} can be computed.
Asymptotically (i.e. for many observations) it has $N-1$ degrees of
freedom for any parameter $\lambda$ drawn from the posterior. Note
that this implies that for bad models and small $N$, one occasionally
obtains a moderate $p$-value although $p\approx 0 $ is expected. This
is especially so for discrete probability models. For those to work
correctly, the \texttt{BCModel} property \verb|flag_discrete| has to
be set to to \texttt{true} (default is \texttt{false}).  To enable the
calculation, the virtual method
%
\begin{verbatim}
double BCModel::CDF(const std::vector<double>& par, int index, bool lower=false)
\end{verbatim}
%
must be overridden in the user model.  \verb|int index| defines the
single data point in the data set. The flag \verb|bool lower| is only
needed for models with discrete probabilities (e.g. Poisson) as
opposed to continuous probability densities (e.g. Gaussian). It
controls whether the CDF is computed not for the actual observation,
but for the hypothetical one with a value just one quantum lower. An
example to clarify this: if in a Poisson process, for bin $2$ a count
of $4$ has been observed, $n_2=4$, then the next lower value is
$n_2=3$.  With the CDF defined, the $p$-value is returned from
%
\begin{verbatim}
double BCModel::GetPvalueFromChi2Johnson(std::vector<double> par)
\end{verbatim}

For \textit{Gaussian} problems (handled by the model
\verb|BCGraphFitter|, sec. \ref{BCGraphFitter}) the standard $\chi^2$
statistic can be used, including the correction for the number of
fitted parameters, from
%
\begin{verbatim}
double BCModel::GetPvalueFromChi2NDoF(std::vector<double> par, int sigma_index)
\end{verbatim}
%
where \verb|sigma_index| is the index of the standard deviation in
each data point.

In the \textit{Poisson} case (described by the model \verb|BCHistogramFitter|)
there are the following three
specific choices to obtain a $p$-value
(for details see \cite{BAT_pValue}, Sec. III.D and IV.B):
\begin{enumerate}
\item
%
\begin{verbatim}
int BCHistogramFitter::CalculatePValueFast(const std::vector<double> &par,
                                           double &pvalue,
                                           int nIterations=100000)
\end{verbatim}
%
which uses a discrete Markov chain to vary the bin counts.
The conditional probability $k$ is then recomputed, and
again the proportion of datasets with lower $k$ is
reported as the $p$-value. A more thorough explanation
of the algorithm is given
in the appendix of \cite{BAT_pValue}.
\item
%
\begin{verbatim}
int BCHistogramFitter::CalculatePValueLikelihood(const std::vector<double> &par,
                                                 double &pvalue)
\end{verbatim}
%
ues the fact that the rescaled likelihood ratio defined in
Eq. (32.12) of \cite{PDGstatistics} has an approximate
$\chi^2$-distribution if all the bin counts aren't too small,
i.e. $n_i \ge 5$.

\item
%
\begin{verbatim}
int BCHistogramFitter::CalculatePValueLeastSquares(const std::vector<double> &par,
                                                   double &pvalue,
                                                   bool weightExpect=true)
\end{verbatim}
%
calculates the sum of squared differences between observed counts and
expected counts, $$\chi^2 = \sum_{i=1}^N \frac{\left(n_i -
\nu_i(\lambda^{*})\right)^2}{\sigma_i^2},$$ where the weights
$\sigma_i$ can be chosen as the expectation values from the Poisson
distribution $\sigma_i^2 = \nu_i$ (\verb|weightExpect=true|) or as the
observed counts, $\sigma_i^2 = n_i$ (\verb|weightExpect=false|).  The
latter choice is especially problematic for no observed count, $n_i
=0$. In that case the weight is arbitrarily set to unity.  $\chi^2$
has an approximate $\chi^2$-distribution with $N-dim(\lambda)$ degrees
of freedom for $n_i>5$.
\end{enumerate}
In all three methods the return value is an integer error code, and
the resulting $p$-value is stored in the reference
\verb|double &pvalue|.  Additionally the cumulative distribution
function is implemented so the $p$-value due to Johnson
\cite{Johnson_pValue} can be obtained directly by calling
\begin{verbatim}
double BCModel::GetPvalueFromChi2Johnson(std::vector<double> par).
\end{verbatim}

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Propagation of uncertainties}

During the marginalization, each point in parameter space is sampled
with a frequency proportional to the posterior pdf at this point. It
is possible in \bat\ to calculate any (user-defined) function of the
parameters during the marginalization and thus obtain a frequency
distribution for the function value(s). This in turn can be
interpreted as the probability density for the function value(s). The
uncertainties on the parameters are thus propagated to the function
under study. An example for the propagation of uncertainties is the
calculation of the uncertainty band for the case of function fitting
(see Section~\ref{subsection:fitting}).  Uncertainty propagation can
be done by overloading\footnote{\code{BCIntegrate} inherits from
  \code{BCEngineMCMC}; \code{BCModel} in turn inherits from
  \code{BCIntegrate}.}
%
\begin{verbatim}
BCEngineMCMC::MCMCUserIterationInterface()
\end{verbatim}
%
which is called at every iteration during the main run of the
MCMC. The user has to loop over all chains and parameters using the
protected variable \verb|fMCMCx|, which is a vector of double values
with a length of the number of chains times the number of
parameters. An example code is given here which calculates a radius in
3D for each iteration (and chain) and fills it into a histogram:

\begin{verbatim}
void MyModel::MCMCIterationInterface()
{
  // get number of chains
  int nchains = MCMCGetNChains();

  // get number of parameters
  int npar = GetNParameters();

  // loop over all chains and fill histogram
  for (int i = 0; i < nchains; ++i) {
    // get the current values of the parameters x, y, z. These are
    // stored in fMCMCx.
    double x = fMCMCx.at(i * npar + 0); // parameter with index 0 in chain i
    double y = fMCMCx.at(i * npar + 1); // parameter with index 1 in chain i
    double z = fMCMCx.at(i * npar + 2); // parameter with index 2 in chain i

    // calculate the radius
    double r = sqrt(x*x + y*y + z*z);

    // fill the histogram
    myHistogramR->Fill(r);
  }
}
\end{verbatim}

An example for the propagation of uncertainties can be found in
\linebreak \verb|examples/basic/errorpropagation|.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{One- and two-dimensional histograms}

The classes \verb|BCH1D| and \verb|BCH2D| are one- and two-dimensional
histogram classes which inherit from the \Root\ classes \verb|TH1D|
and \verb|TH2D|. They are filled, e.g., during marginalization. To
change the number of bins used for a particular parameter use
%
\begin{verbatim}
void BCModel::SetNbins(const char * parname, int nbins).
\end{verbatim}
%
Pointers to the \Root\ histograms can be returned
using
%
\begin{verbatim}
TH1D * BCH1D::GetHistogram(),
TH2D * BCH2D::GetHistogram().
\end{verbatim}
%
For one-dimensional histograms, once the histograms are filled,
summary information can be obtained by
%
\begin{verbatim}
double BCH1D::GetMean(),
double BCH1D::GetMode(),
double BCH1D::GetMedian(),
\end{verbatim}
%
and the quantiles of the distribution can be returned using
%
\begin{verbatim}
double BCH1D::GetQuantile(double probability),
\end{verbatim}
%
where \verb|probability| is a number between~0 and~1. This information
can be used to estimate uncertainties (e.g., the central 64\%
probability region) or limits on parameters (e.g., the quantile for
0.95). Alternatively, the smallest set of intervals containing a
certain probability can be obtained by
%
\begin{verbatim}
double BCH1D::GetSmallestInterval(double & min, double & max, double content=0.68).
\end{verbatim}

Both types of histograms can be drawn to a \Root\ \verb|TCanvas| using
the methods
%
\begin{verbatim}
BCH1D::Draw(int options=0, double ovalue=0.),
BCH2D::Draw(int options=0, bool drawmode=true),
\end{verbatim}
%
where the options are summarized in Table~\ref{table:printingoptions}.

\begin{table}[ht!]
\begin{tabular}{ll}
\hline
Option & Style \\
\hline
BCH1D & \\
\hline
0 (default) & \begin{minipage}[l]{12 cm}Draws a colored band at the central 68\% probability region. If the mode is not inside this band, the 95\% probability limit is drawn. \end{minipage}\\
1           & Draws a line at the value passed. \\
2           & Draws a colored band at the smallest interval containing \verb|ovalue|\% probability. \\
\hline
BCH2D & \\
\hline
0 (default) & Draw with the \Root\ option \verb|CONT0|. \\
1           & Draw the 68\%, 95\% and 99\% probability contours. \\
2           & Draw the 68\% probability contour. \\
3           & Draw the 90\% probability contour. \\
4           & Draw the 95\% probability contour. \\
\hline
\end{tabular}
\caption{Printing options for one- and two-dimensional histograms.
\label{table:printingoptions}}
\end{table}

% --------------------------------------------------------

%\subsection{Single event analyses and sensitivity studies}
%\label{subsection:singleeventanalyses}

%Often one is interested in repeating the same analysis on several data
%sets. This is particularly true for estimating the expected outcome of
%an analysis given a particular set of input parameters, e.g. to study
%the sensitivity of an experiment to a certain process. \bat\ offers an
%easy way to handle such processes and the outcome.

%If a data set contains several data points and one data point
%describes the possible outcome of an experiment then one can use
%%
%\begin{verbatim}
%BCModel::SetSingleDataPoint(BCDataPoint * datapoint)
%BCModel::SetSingleDataPoint(BCDataSet * dataset, int index)  .
%BCModelManager::SetSingleDataPoint(BCDataPoint * datapoint)
%BCModelManager::SetSingleDataPoint(BCDataSet * dataset, int index)  .
%\end{verbatim}
%%
%The data set of the model (or model manager) will be set to a single
%event from the given data set. This allows to loop over the events of
%a data set without reloading and redefining it for each analysis.
%
%See \verb|example05| for an application of these features.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% Tools and models
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\clearpage
\pagebreak

\section{Tools and models}
\label{section:tools}

\subsection{Tools}
\label{subsection:tools}

\subsubsection{The summary tool}

A summary tool, \verb|BCSummaryTool|, is provided with \BAT, which
summarizes the results of the marginalization. It creates a set of
plots and tables. An instance of the class can be created by
%
\begin{verbatim}
BCSummaryTool() ,
BCSummaryTool(BCModel * model);
\end{verbatim}
%
If the model is not set during construction it can be set using the
method
%
\begin{verbatim}
void BCSummaryTool::SetModel(BCModel * model) .
\end{verbatim}

After the marginalization of the posterior has been performed, a
set of plots can be produced with the following methods:
%
\begin{itemize}
\item \verb|int BCSummaryTool::PrintParameterPlot(const char* filename="parameters.eps")|\\
  Creates an overview plots of the marginalized mode, standard
  deviation, the most important quantiles and the global mode for all
  parameters.

\item \verb|int BCSummaryTool::PrintCorrelationPlot(const char* filename="correlation.eps")|\\
  Prints a two-dimensional correlation matrix of the parameters.

\item \verb|int BCSummaryTool::PrintKnowlegdeUpdatePlots(const char* filename="update.eps")|\\
  Prints the marginalized distributions for the prior and posterior
  probablity. This illustrates the update in knowledge due to the
  data. Calling this function will re-run the analysis without the use
  of the \verb|LogLikelihood| information.
\end{itemize}

In addition, a latex table of the parameters and the results can be
produced with the method:
%
\begin{verbatim}
int BCSummaryTool::PrintParameterLatex(const char * filename) .
\end{verbatim}

\subsection{Models for function fitting}
\label{subsection:fitting}

A common application in data analysis is fitting a function, $y(x)$,
to a (one-dimensional) distribution or a set of data
points. \bat\ offers three dedicated tools for this purpose, depending
on the uncertainties on each data point. These classes and the assumed
uncertainties are summarized in the following.

In all three cases, the uncertainties for each data point (or bin
content) are assumed to be independent of each other. I.e., in the
case of histograms bin-by-bin migration is not included. The overall
conditional probability is a product of the individual probabilities
for the expectation value given the $y$-value (or bin content).

An uncertainty band is calculated for each fit. During the
marginalization, each point in parameter space is sampled with a
frequency proportional to the posterior pdf at this point (if the
Markov chain has converged). The uncertainty band is obtained by
evaluating the fit function, $y(x)$, for each $x$ at each point in
parameter space. The values are histogrammed in
$x$--$y(x)$--space. Each slice of $x$ is normalized to unity and
interpreted as probability density for $y$ given $x$. The~0.16 and
0.84~quantiles are then interpreted as the uncertainty on $y$ at that
particular $x$. The uncertainty band can be returned from a model
using
%
\begin{verbatim}
TGraph * BCModel::GetErrorBandGraph(double level1, double level2) ,
\end{verbatim}
%
where the levels correspond to the quantiles of the distribution
$p(y(x))$ (default: 0.16 and 0.84).

In all three cases, the fast methods for evaluating the $p$-value are
implemented. The $p$-value is evaluated automatically and returned
together with a summary.

% --------------------------------------------------------
\subsubsection{The Gaussian case}
\label{BCGraphFitter}

The class \verb|BCGraphFitter| allows to fit a \Root\ function
(\verb|TF1|) to a \Root\ graph (\verb|TGraphErrors|). The
uncertainties on $y$ at a given $x$, defined by the uncertainties of
the \verb|TGraphErrors|, are assumed to be Gaussian, i.e., the
uncertainty on $y$ corresponds to the width, $\sigma$, of the
Gaussian. The uncertainties on $x$ are not taken into account.  An
example for this fitter can be found in
\verb|examples/basic/graphFitter|.


% --------------------------------------------------------
\subsubsection{The Poissonian case}

The class \verb|BCHistogramFitter| allows to fit a \Root\ function
(\verb|TF1|) to a \Root\ histogram (\verb|TH1D|). The uncertainty on
the expectation value in each bin is assumed to be Poissonian, and
thus non-symmetric around the number of entries in this bin.  An
example for this fitter can be found in
\verb|examples/basic/histogramFitter|.


% --------------------------------------------------------
\subsubsection{The Binomial case}

The class \verb|BCEfficiencyFitter| allows to fit a \Root\ function
(\verb|TF1|) to the ratio of two \Root\ histograms (\verb|TH1D|). The
uncertainty on the expectation value in each bin is assumed to be
Binomial, and thus non-symmetric around the ratio of entries in this
bin. The ratio is assumed to be between 0 and 1, i.e., one histogram
contains a subset of the other.  An example for this fitter can be
found in \verb|examples/basic/efficiencyFitter|.

\subsection{A model for template fitting}

A model for template fitting, \verb|BCTemplateFitter|, is provided
with BAT. A description of the method can be downloaded on the web
page. Three working examples are provided with the current release in
\verb|examples/advanced/templatefitter|.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% output
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\clearpage
\pagebreak

\section{Output}
\label{section:output}

\subsection{Log file}
\label{subsection:logfile}

The class \verb|BCLog| is used to write out information during the
runtime of the program. The output is written to screen and to a log
file. The level of detail can be set independently for both
via
%
\begin{verbatim}
void BCLog::SetLogLevelFile(BCLog::LogLevel loglevel),
void BCLog::SetLogLevelScreen(BCLog::LogLevel loglevel),
\end{verbatim}
%
where the level is one of the following
%
\begin{itemize}
\item \verb|debug|: Lowest level of information.
\item \verb|detail|: Details of functions, such as the status of the
  Markov chains, etc.
\item \verb|summary|: Results, such as best-fit values, normalization, etc.
\item \verb|warning|: Warning messages
\item \verb|nothing|: Nothing is written out.
\end{itemize}

A log file has to be opened in the beginning of the main file using
%
\begin{verbatim}
void BCLog::OpenLog(const char * filename).
\end{verbatim}

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Summary information}

A summary of the MCMC run can be written to file or printed to the
screen using
%
\begin{verbatim}
void BCModel::PrintSummary(),
void BCModel::PrintSummary(const char * file).
\end{verbatim}

The summary contains information about the convergence status, the
models, their parameters and respective ranges as well as information
about the marginalization (e.g., mean and rms, median and central 68\%
interval, and the smallest interval containing 68\% probability). The
results of the global maximization of the posterior probability is
also summarized.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Histograms}

Histograms of the marginalized distributions can be written to an
eps file with the functions
%
\begin{verbatim}
int BCModel::PrintAllMarginalized1D(const char * filebase),
int BCModel::PrintAllMarginalized2D(const char * filebase),
int BCModel::PrintAllMarginalized(const char * file, int hdiv=1, int ndiv=1),
\end{verbatim}
%
where \verb|file| (or \verb|filebase|) is the filename and \verb|hdiv|
and \verb|ndiv| define the number of divisions in the
plots. Alternatively, the histograms can be obtained from the model
(see section~\ref{subsubsection:marginalization}) and then plotted,
printed or stored in a \Root\ file.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{The output class}
\label{section:outputclass}

The results of an analysis can be stored in a \Root\ file using the
output class \verb|BCModelOutput|. This class is assigned a model
class and a file. It contains a \Root\ tree which stores the most
important information of the analysis outcome, such as the global
mode, the marginalized mode, means, limits, etc. The constructors are
%
\begin{verbatim}
BCModelOutput()
BCModelOutput(BCModel * model, const char * filename).
\end{verbatim}
%
The model and filename can be set after construction using
%
\begin{verbatim}
BCModelOutput::SetModel(BCModel * model),
BCModelOutput::SetFile(const char * filename).
\end{verbatim}
%
The marginalized distributions can also be stored in the output file
using
%
\begin{verbatim}
BCModelOutput::WriteMarginalizedDistributions().
\end{verbatim}

The single points of the Markov Chain(s) can also be stored in the
output file together with the posterior probability at these
points. This can be done by setting a flag before the Markov Chain is
run:
%
\begin{verbatim}
BCModelOutput::WriteMarkovChain(bool flag = true).
\end{verbatim}
%
Please note that the file size can be large in case you chose this
options. Each chain is stored as a \Root\ tree. This option allows for
offline diagnostics of the chains. The variables stored are:

\begin{itemize}
\item Phase: describes the phase of the running (1: pre-run, 2: main run),
\item Cycle: described the cycle of the chain in the pre-run,
\item Iteration: the current iteration number,
\item NParameters: the number of parameters,
\item LogProbability: the log of the posterior probability,
\item Parameter{\it i}: the parameter value of the {\it i}th parameter.
\end{itemize}

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% settings
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\section{Settings, options and special functions}
\label{section:settings}

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{ Markov Chain settings and options}
\label{section:settings:MCMC}

The most important options for the Markov Chains are listed here. For
further reference see the reference guide:
%
\begin{itemize}

\item \verb|BCEngineMCMC::SetNChains(int n)| Sets the number of chains
  which are run in parallel (default: 5).

\item \verb|BCEngineMCMC::MCMCSetNIterationsMax(int n)| Sets the maximum
  number of iterations of the pre-run (default: 1,000,000).

\item \verb|BCEngineMCMC::MCMCSetNIterationsRun(int n)| Sets the number of
  iterations of the analysis run (default: 100,000).

\item \verb|BCEngineMCMC::MCMCSetNIterationsUpdate(int n)| Sets the number
  of iterations (default: 1,000) after which the chains are updated in
  the pre-run (e.g., for the calculation of the efficiency and
  convergence tests). Note that if there are $k$ parameters, each changed one
  at a time, the actual number of posterior evaluations between
  two convergence checks is $\min \left(k \cdot n, 10000\right)$, where $n$ is the number of iterations in
  which a new value of exactly one of the $k$ parameters is proposed.

\item \verb|BCEngine::MCMCSetFlagOrderParameters(bool flag)|. Decides
  if all parameters should be varied one after each other (true) or
  all at the same time (default: true).

\item \verb|BCEngineMCMC::MCMCSetFlagInitialPosition(int flag)| Decides how
  to chose the initial positions (0: center of the parameter
  boundaries, 1: random positions (default), 2: user defined
  positions).

\item \verb|BCEngineMCMC::MCMCSetFlagFillHistograms(int index, bool flag)| and \\
  \verb|BCEngineMCMC::MCMCSetFlagFillHistograms(bool flag)|. Set flag to fill the marginalized distribution for a single or all parameters. Not filling the distributions might increase the speed of MCMC run.

\item \verb|BCEngineMCMC::MCMCSetInitialPositions(std::vector<double> x0s)|
  and \\
  \verb|MCMCSetInitialPositions(std::vector< std::vector<double> > x0s)|
  Set the initial positions of all parameters in all chains.

\item \verb|BCEngineMCMC::MCMCSetMinimumEfficiency(double efficiency)| and \\
  \verb|MCMCSetMaximumEfficiency(double efficiency)|. Set the minimum
  (default: 15\%) and maximum (default: 50\%) efficiency of the Markov
  Chains. The efficiency found in the pre-run has to be within these
  limits otherwise the pre-run continues.

\item \verb|BCEngineMCMC::MCMCSetRValueCriterion(double r)| Set the
  $R$-value criterion for convergence of a set of chains (default:
  0.1).

\item \verb|BCEngineMCMC::MCMCSetRValueStrict(bool flag)| Calculate the
  $R$-value criterion for convergence with the strict definition (true)
  by~\cite{R_value}  or use a relaxed version (false) which doesn't guarantee
  $R \ge 1$, but allows for similarly robust convergence checking in slightly
  less iterations. (default: relaxed definition)

\item \verb|BCEngineMCMC::MCMCSetTrialFunctionScaleFactor(std::vector <double> scale)|
  Set the the initial scale for all one dimensional proposal functions (default: 1).
  BAT updates the individual scales until the efficiency is in the desired range
  (see also \\ \verb|BCEngineMCMC::MCMCSetMinimumEfficiency|). If it is known that the.
  support of the posterior concentrates in a small region of parameter space,.
  setting the scales to a value smaller than 1 will help the chain to achieve.
  the desired efficiency faster. Alternatively, one can shrink the parameter range.

\item \verb|BCEngineMCMC::WriteMarkovChain(bool flag)|. Set a flag to
 write the Markov Chain into a ROOT file. See
 section~\ref{section:outputclass} on how to handle output in BAT.

\item
  \verb|BCEngineMCMC::MCMCSetPrecision(BCEngineMCMC::Precision precision)|. Set
  predefined values for running the algorithm with different
  precision. Possible varguments are \linebreak \verb|BCEngineMCMC::kLow| (for
  quick runs), \verb|BCEngineMCMC::kMedium| (for ``normal'' running),
  \linebreak \verb|BCEngineMCMC::kHigh| (for publications).

\item \verb|BCEngineMCMC::MCMCGetTRandom3()|. Returns the random number
generator used with the Markov chain. The default seed is 0, i.e.,
it is randomly initialized. To obtain reproducible results, use
a non-zero seed. E.g.
\verb|m->MCMCGetTRandom3()->SetSeed(21340);|.
\end{itemize}

\paragraph{Proposal function}

The proposal function is set to a Breit-Wigner function per
default. The width of the Breit-Wigner is adjusted during the pre-run
to match the required efficiency of the sampling. The user can
overload the method
%
\begin{verbatim}
void BCEngineMCMC::MCMCTrialFunction(int chain, std::vector <double> &x)
void BCEngineMCMC::MCMCTrialFunctionSingle(int ichain,
                                           int iparameter,
                                           std::vector <double> &x)
\end{verbatim}

The first method is used in the case of unordered sampling, the second
one for ordered sampling. The vector $\verb|x|$ is filled with a
random number preferably in the range of 0~to~1. The numbers will be
scaled to the valid parameter range. An example for changing the trial
function can be found in \verb|examples/expert/TrialFunction|.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Settings and options for Simulated Annealing}
\label{section:settings:SA}

The most important options for the implemented Simulated Annealing
algorithm are listed here. For further reference see the reference
guide:
%
\begin{itemize}
\item \verb|BCIntegrate::SetSASchedule(BCIntegrate::BCSASchedule)|. Set the
  annealing schedule. This could be \verb|BCIntegrate::kSACauchy|,
  \verb|BCIntegrate::kSABoltzmann|, \verb|BCIntegrate::kSACustom|.
\item \verb|BCIntegrate::SetSAT0(double T0)|. Set the starting
  temperature.
\item \verb|BCIntegrate::SetSATmin(double Tmin)|. Set the threshold
  temperature.
\item \verb|BCIntegrate::SetFlagWriteSAToFile(bool flag)|. Set a flag to
 write the individual steps of the simulated annealing into a ROOT
 file. See section~\ref{section:outputclass} on how to handle output in
 BAT.
\end{itemize}

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

%\subsection{Special functions}

% --------------------------------------------------------
% Technical tools
% --------------------------------------------------------
%\section{Technical tools}
%\label{section:tools}

%{\it Save all this for a later version of the manual.}

%\subsection{Optimization}

%\subsection{Markov Chain Monte Carlo}

%\subsection{Integration}

% --------------------------------------------------------
% More features
% --------------------------------------------------------
%\section{More features}
%\label{section:features}

%{\it Save all this for a later version of the manual.}

%\subsection{Normalization}

%\subsection{Model comparison}

%\subsection{Fitting}

%\subsection{Single event analysis}

%\subsection{User defined data interface}

% --------------------------------------------------------
% bibliography
% --------------------------------------------------------

\addcontentsline{toc}{section}{Bibliography}

\begin{thebibliography}{99}
\bibitem{Caldwell:2008fw}
  A.~Caldwell, D.~Kollar and K.~Kroeninger, ``BAT - The Bayesian
  Analysis Toolkit,'' \textit{Comp.\ Phys.\ Comm.}\ {\bf 180} (2009) 2197-2209
  [arXiv:0808.2552]
  \url{http://www.mpp.mpg.de/bat/}
%
\bibitem{ROOTweb}
  \url{http://root.cern.ch/}
%
\bibitem{CUBA}
  T.~Hahn, ``CUBA: A library for multidimensional numerical
  integration,'' \textit{Comp.\ Phys.\ Comm.}\ {\bf 168} (2005) 78
  [arXiv:hep-ph/0404043].
%
\bibitem{CUBAweb}
  \url{http://www.feynarts.de/cuba/}

\bibitem{PDGstatistics}
Particle Data Group, Mathematical Tools or Statistics, Monte Carlo, Group Theory, Physics Letters B, Volume 667, Issues 1-5, Review of Particle Physics, 11 September 2008, Pages 316-339, ISSN 0370-2693, DOI: 10.1016/j.physletb.2008.07.030.
(http://www.sciencedirect.com/science/article/B6TVN-4T4VKPY-G/2/32a7641753a1a6d41124d1992263243a)

\bibitem{BAT_pValue}
F.~Beaujean and A.~Caldwell and D.~Koll{\'a}r and K.~Kr{\"o}ninger,
``$p$-values for model evaluation'', \textit{Phys.\ Rev.\ D} {\bf 83} (2011)
[arxiv:1011.1674]

\bibitem{Johnson_pValue}
V.E. Johnson,  A Bayesian chi2 Test for Goodness-of-Fit. The Annals of Statistics 32, 2361-2384(2004).

\bibitem{R_value}
A. Gelman and D. B. Rubin, ``Inference from Iterative Simulation Using Multiple Sequences,`` \emph{Statistical Science}   {\bf 7} (1992) 4,  457-472.


\end{thebibliography}

% --------------------------------------------------------

\end{document}


