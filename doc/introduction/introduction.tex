\documentclass[11pt, a4paper]{article}

%\usepackage{geometry}
%\usepackage{epsfig}
%\usepackage{epstopdf}
%\usepackage{graphics}
\usepackage{graphicx}

\setlength{\oddsidemargin}{0cm}
\setlength{\evensidemargin}{0cm}
\setlength{\topmargin}{-1cm}
\setlength{\textheight}{23cm}
\setlength{\textwidth}{16cm}

\pagestyle{headings}

\newcommand{\bat}{{\sc BAT}}
\newcommand{\Root}{{\sc Root}}
\newcommand{\versionno}{0.2.1}
\newcommand{\version}{version~\versionno}
\newcommand{\Version}{Version~\versionno}

%--------------------------------------------------------

\begin{document}

% --------------------------------------------------------
% title
% --------------------------------------------------------

\thispagestyle{empty}

\begin{figure}
\includegraphics[scale=0.25]{bat.eps}
\end{figure}

\vspace{1.0cm}

\begin{center}

{\Large \bat\ - a short introduction}

\end{center}

\thispagestyle{empty}

\vspace{17.0cm}

\begin{center}
\today
\end{center}

\pagebreak

% --------------------------------------------------------
% table of contents
% --------------------------------------------------------

\thispagestyle{empty}

\tableofcontents

\pagebreak

% --------------------------------------------------------
% introduction
% --------------------------------------------------------
\section{Introduction}
\label{section:introduction}

The Bayesian Analysis Toolkit, \bat, is a software package designed to
help solve statistical problems encountered in Bayesian
inference. Allowing to formulate models and their parameters, the main
purpose of the toolkit is to provide methods to solve the numerical
optimization and integration. It features the possiblity to estimate
parameters and to compare models. A procedure to estimate the
goodness-of-fit is included and based on ensemble tests. A detailed
introduction to \bat\ can be found in~\cite{Caldwell:2008fw}.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% installation
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\section{Installation}
\label{section:installation}

\subsection{Platforms}

\bat\ has been developed on Linux machines running different distributions
and different versions of the kernel and gcc. As far as we know there
is nothing distribution dependent inside of \bat. However, we have not
yet started to systematically check for compatibility and
portability. This is planned for future releases of \bat. For the
moment the only statement we can do here is that if you don't have a
too old or too specific installation of Linux you should be able to
compile and use \bat\ without problems. \\ 

Windows is not supported for the moment. 

% -------------------------------------------------------- 
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% -------------------------------------------------------- 

\subsection{Dependencies}

\subsubsection{\Root} 
\Root\ is an object oriented data analysis framework. You can obtain it
from~\cite{ROOTweb}. To compile and run \bat\ you will need a \Root\
version 5.16 or later. Please, check your Linux distribution for the
availability of precompiled packages on your system. Mostly used
distributions nowdays have the \Root\ packages available

% -------------------------------------------------------- 
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% -------------------------------------------------------- 

\subsection{Recommendations}

\paragraph{CUBA:}
CUBA~\cite{CUBA} is a library containing general purpose
multidimensional integration algorithms. It can be obtained
from~\cite{CUBAweb}. In this version \bat\ no longer depends on CUBA
and you can compile and run without it. However, the use of CUBA is
recommended as it provides integration routines tuned for performance,
which are very usefull for integration in problems with large number
of dimensions. \\

Note: Since version 1.5 the compilation of CUBA no longer crashes if
you don't have Mathematica installed. To compile and install CUBA
libraries use commands 'make lib ; make install'.

% -------------------------------------------------------- 
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% -------------------------------------------------------- 

\subsection{Installation procedure}

Unpack the tarball containing the \bat\ source usually named like
BAT-x.x.tar.gz (here x.x is the version number) using command
%
\begin{verbatim}
tar -xzf BAT-x.x.tar.gz
\end{verbatim}
%
A directory called BAT-x.x will be created containing the source code.
Enter the directory and run the configuration using commands
%
\begin{verbatim}
cd -x.x
./configure
\end{verbatim}

This will check your system for all components needed to compile \bat\
and set up the paths for installation. You can add option
\verb|--prefix=/path/to/install/bat| to \verb|./configure| to specify
the the prefix to the \bat\ installation path. The \bat\ library files
will be installed to \verb|$prefix/lib| and the include files to
\verb|$prefix/include|. Default installation prefix is
\verb|/usr/local|. \\ 

The configure script checks for \Root\ availability in the system and
fails if \Root\ is not installed. You can specify the ROOTSYS directory
using \verb|--rootsys=/path/to/rootsys|. \\ 

The configure will also search for \verb|libcuba.a| and \verb|cuba.h|
in the system.  The \verb|libcuba.a| has to be available in the
standard system library search path. You can specify the \verb|cuba.h|
location using \verb|--with-cuba-path=/path/to/cuba/header|. \\ 

After successful configuration run
%
\begin{verbatim}
make
make install
\end{verbatim}
%
to compile and install \bat. Note that depending on the setting of
installation prefix you might need root priviledges to be able to
install \bat. If you are installing \bat e.g. in your
\verb|\$HOMEDIR|, you need to add the path to the library and to the
include files to the search path in your system. Depending on your
shell you can do that via commands
%
\begin{verbatim}
export BATINSTALLDIR=/bat/install/prefix
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$BATINSTALLDIR/lib
export CPLUS_INCLUDE_PATH=$CPLUS_INCLUDE_PATH:$BATINSTALLDIR/include
\end{verbatim}
%
or
%
\begin{verbatim}
setenv BATINSTALLDIR       /bat/install/prefix
setenv LD_LIBRARY_PATH     $LD_LIBRARY_PATH:$BATINSTALLDIR/lib
setenv CPLUS_INCLUDE_PATH  $CPLUS_INCLUDE_PATH:$BATINSTALLDIR/include
\end{verbatim}
%
for bash and csh compatible shells, respectively. \\ 

An option for use in compiled programs would also be to add
\verb|-I/bat/install/include/path| to \verb|CFLAGS| and
\verb|-L/bat/install/lib/path| to \verb|LDFLAGS| in your
\verb|Makefile|. However, the interactive \Root\ macros will not work if
\verb|libBAT.so| and \verb|libBAT.rootmap| both aren't in the system
library search path. \\ 

See also \verb|doc/INSTALL| for installation instructions.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% analysis chain
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\pagebreak  

\section{Running \bat}
\label{section:running}

\subsection{The analysis chain} 
\label{subsection:chain}

The typical analysis chain in \bat\ is the following: one or several
models are defined together with their parameters and corresponding
ranges. Data is read in from a file and interfaced with each
model. For each model parameters are estimated either from the
posterior probability density or from the marginalized probability
densities of the individual parameters. Model can be compared using
direct probabilities or Bayes factors. A ``goodness--of--fit'' test
can be performed by evaluating the likelihood for an ensemble of
possible data sets given the best-fit parameters. The data sets are
generated under the assumption of the model at hand and the best-fit
parameters. \\

% -------------------------------------------------------- 
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% -------------------------------------------------------- 

\subsection{Getting started} 
\label{subsection:start}

\bat\ comes in form of a library. It can be linked against in any
existing C++ code, or it can be used in an interactive
\Root\ session. The latter case is discussed later on in this
manual. Several files need to be provided by the user in order to
start a new project:
% 
\begin{itemize}
\item A makefile in which the \bat\ library is linked. 
\item Include and source files of the classes defining the models
used in the analysis (see next section). 
\item A main file in which the actual analysis is performed. 
\end{itemize} 
%
The script \verb|BAT/tools/CreateProject.sh| can be used to create an
empty analysis skeleton including the above listed files.

% -------------------------------------------------------- 
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% -------------------------------------------------------- 

\subsection{Creating a model} 
\label{subsection:model}

% -------------------------------------------------------- 

\subsubsection{Implementation of a mathematical model as a C++ class} 
\label{subsubsection:implementation}

The mathematical models used in \bat\ are implemented in terms of C++
classes. All model classes inherit from the class \verb|BCModel|. This
base class has several public member functions which need to be
overloaded by the user in order to specify the mathematical
expressions for an unambiguous definition of the model. Apart from the
constructor and destructor, these methods are
% 
\begin{itemize}
\item \verb|void BCModel::DefineParameters()| \\
This method has to be called at construction and contains the
definition of parameters.
% 
\item
  \verb|double BCModel::LogLikelihood(std::vector <double> parameters)|
  \\ This method contains a mathematical expression for the
  conditional probability of the data given a set of parameter values,
  $p(x|\vec{\lambda})$. It returns the logarithm of the conditional
  probability For reasons of numerical stability. 
%
\item
  \verb|double BCModel::LogAPrioriProbability(std::vector <double> parameters)|
  \\ This method contains a mathematical expression for the {\it a
    priori} probability for a set of parameter values. It returns the
  logarithm of the conditional probability for reasons of numerical
  stability.
\end{itemize} 

\noindent 
A class derived from \verb|BCModel| can contain any number of
additional member functions.

% -------------------------------------------------------- 

\subsubsection{Definition of parameters of a model} 
\label{subsubsection:parameters}

The parameters of a model are implemented as a C++ class named
\verb|BCModelParameter|. They can be interfaced to a model in two
ways: parameters can be defined explicitly and then added to a model
via
%
\begin{verbatim}
BCParameter * parameter = new BCParameter(const char* name, 
                                          double lowerlimit, double upperlimit); 
BCModel::AddParameter(BCParameter * parameter),
\end{verbatim}

\noindent 
where the arguments in the first case are the name of the parameter,
and the lower and upper limit of the parameter,
respectively. Parameters can also be defined implicitly via
%
\begin{verbatim}
BCModel::AddParameter(const char* name, double lowerlimit, double upperlimit) . 
\end{verbatim}

\noindent 
Every parameter has to have a unique name and valid limits. Once added
to a model each parameter is given a unique index starting at zero. A
parameter can be referenced to by its index or by its name. It can be
returned from a model using the methods
% 
\begin{verbatim} 
BCModel::GetParameter(int index), 
BCModel::GetParameter(char* name). 
\end{verbatim}  

% -------------------------------------------------------- 
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% -------------------------------------------------------- 

\subsection{Data} 
\label{subsection:data} 

\subsection{Data format and handling} 
\label{subsection:dataformat} 

Data is managed in the form of data points which are combined to data
sets. Data points and sets are implemented as classes
\verb|BCDataPoint| and \verb|BCDataSet|, respectively. \\ 

\noindent 
The class \verb|BCDataPoint| contains a set of double precision
values. Data points can be generated explicitly by the user with or
without intial value
%
\begin{verbatim} 
BCDataPoint::BCDataPoint(int nvariables) ,
BCDataPoint::BCDataPoint(vector<double> x) .  
\end{verbatim} 

\noindent 
Values of a data point can either be set value-by-value or for all
values at once
%
\begin{verbatim} 
BCDataPoint::SetValue(int index, double value) , 
BCDataPoint::SetValues(std::vector <double> values) . 
\end{verbatim} 

\noindent 
The value of the $i$th entry can be obtained by 
%
\begin{verbatim}
BCDataPoint::GetValue(int index) . 
\end{verbatim} 

\noindent 
A data point can be added to a data set with the method

\begin{verbatim} 
BCDataSet::AddDataPoint(BCDataPoint* datapoint) . 
\end{verbatim} 

\noindent 
Alternatively, data can be read in from a file
%
\begin{verbatim}
BCDataSet::ReadDataFromFile(char* filename, 
													  char* treename, const char* branchnames) ,
BCDataSet::ReadDataFromFile(char* filename, int nvariables) .
\end{verbatim} 

\noindent 
The data format for ASCII files is such that each data point
corresponds to one line, each containing several values. Note that the
number of values per data point has to be provided by the user. \\

\noindent 
Once a data set is defined it can be assigned to a model with
%
\begin{verbatim}
BCModel::SetDataSet(BCDataSet* dataset) . 
\end{verbatim} 

\noindent 
Similarly, a data set can be returned from a model with 
%
\begin{verbatim}
BCModel::GetDataSet() . 
\end{verbatim} 

\noindent 
Note that the user can define several data sets. However, a model can
only have one data set at a time. This data set can be accessed in the
overloaded method \verb|BCModel::LogLikelihood()|.

% --------------------------------------------------------

\subsubsection{Constraining the values of data points}

For two applications discussed later in this section, the
goodness-of-fit test and the calculation of error bands, it is
necessary to define the limits of the data points. This is done for
each variable separately. Note that the limits are defined by the
model, not by the data set:
%
\begin{verbatim}
BCModel::SetDataBoundaries(int index, double lowerboundary, 
													 double upperboundary) . 
\end{verbatim}

% -------------------------------------------------------- 
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% -------------------------------------------------------- 

\subsection{Managing more than one model: the model manager} 
\label{subsection:modelmanager}

In case more than one model is defined and all models use the same
data set a model manager can be defined. It is implemented as a class
named \verb|BCModelManager|. Models and their (model) prior
probability are added to the model manager via
% 
\begin{verbatim}
BCModelManager::AddModel(BCModel * model, double probability) , 
BCModelManager::AddModel(BCModel * model) , 
\end{verbatim} 

\noindent 
where \verb|probability| is the prior probability for the model. A
common data set can be defined and will be patched through to all
models added to the manager class. This can either be done explicitly
via
%
\begin{verbatim}
BCModelManager::SetDataSet(BCDataSet * dataset) , 
\end{verbatim} 

\noindent 
or by reading data from a file via 
%
\begin{verbatim}
BCModelManager::ReadDataFromFile(char* filename, char* treename, 
																 const char* branchnames) , 
BCModelManager::ReadDataFromFile(char* filename, int nvariables) . 
\end{verbatim} 

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% -------------------------------------------------------- 

\subsection{Normalization and numerical integration} 
\label{section:normalization} 

The posterior pdf is normalized to unity in Bayes' Theorem. The
normalization is an integral of the conditional probability times the
prior probability over the whole parameter range. Since the analytical
form of the integral is not known in general this integral is solved
numerically. Several methods for numerical integration are implemented
in the package and can be chosen by
%
\begin{verbatim}
BCModel::SetIntegrationMethod(BCModel::BCIntegrationType method), 
\end{verbatim} 

\noindent
where \verb|BCIntegrationType| can be one of the following 
% 
\begin{itemize}
\item \verb|BCModel::kIntMonteCarlo|. A sampled mean integration.
\item \verb|BCModel::kIntImportance|. A sampled mean integration
 with importance sampling.  
\item \verb|BCModel::kIntMetropolis|. A sampled mean integration
 with importance sampling using Markov chains. 
\item \verb|BCModel::kIntCuba|. An interface to the CUBA
  library~\cite{CUBA,CUBAweb}.
\end{itemize}

\noindent 
The normalization can be performed for each model separately or for
all models which belong to a model manager:
%
\begin{verbatim}
BCModel::Normalize() ,
BCModelManager::Normalize() .
\end{verbatim} 

\noindent 
The normalization is stored for each model. The value can be obtained
by
%
\begin{verbatim}
double BCModel::GetNormalization() . 
\end{verbatim}

\noindent 
Once the integral is calculated the posterior pdf for a set of
parameter values can be evaluated
%
\begin{verbatim} 
BCModel::Probability(std::vector <double> parameter) , 
BCModel::LogProbability(std::vector <double> parameter) , 
\end{verbatim} 
%
where the latter returns the logarithm of the posterior pdf.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% -------------------------------------------------------- 

\subsection{Parameter estimation and marginalization} 

The posterior pdf can be used to estimate the set of parameter values
most suited to describe the data. This is done by searching for the
most probable value, or mode, of the posterior pdf. Two approaches are
followed: either the mode in the whole parameter space is searched
for, or the pdf is marginalized with respect to the particular
parameter under study. In the latter case, several quantities can used
to describe the marginalized distributions.

% --------------------------------------------------------

\subsubsection{Maximization of the full posterior probability density} 

The maximization of the full posterior pdf can be performed using the
method
%
\begin{verbatim} 
BCModel::FindMode() . 
\end{verbatim} 

\noindent 
The vector of parameter values which maximizes the posterior pdf can be obtained using 
%
\begin{verbatim}
std::vector <double> BCModel::GetBestFitParameters() , 
double BCModel::GetBestFitParameter(unsigned int index) .
\end{verbatim}
%
The implemented algorithms can be chosen with the command
%
\begin{verbatim}
BCModel::SetOptimizationMethod(BCIntegrate::BCOptimization method) .
\end{verbatim}
%
Three methods are available in the current version (\Version): 
%
\begin{itemize}
\item \verb|BCModel::kOptMetropolis|. A sampling algorithm using the
  Metropolis alogorithm.
\item \verb|BCModel::kOptMinuit|. An interface to the \Root\ version
  of Minuit.
\item \verb|BCModel::kOptSA|. A Simulated Annealing algorithm. 
\end{itemize}
%
If the interface to Minuit is used the estimated uncertainties on the
parameters can be obtained using
%
\begin{verbatim}
std::vector <double> BCModel::GetBestFitParameterErrors() , 
double BCModel::GetBestFitParameterError(unsigned int index) . 
\end{verbatim}
%
Settings and options of the Simulated Annealing algorithm are
summarized in section~\ref{section:settings:SA}.

% --------------------------------------------------------

\subsubsection{Marginalization} 
\label{subsubsection:marginalization}

\noindent 
The single parameter estimation is done via marginalization. If more
than one parameter is studied it is most efficient to marginalize with
respect to all parameters simultaneously. This can be done using
%
\begin{verbatim}
BCModel::MarginalizeAll() . 
\end{verbatim} 

\noindent 
One- and two-dimensional histograms are filled during the
marginalization. They can be accessed by
%
\begin{verbatim}
BCModel::GetMarginalized(BCParameter * parameter) ,
BCModel::GetMarginalized(char * name) ,
BCModel::GetMarginalized(BCParameter * parameter1, BCParameter * parameter2) ,
BCModel::GetMarginalized(char * name1, char * name2) .
\end{verbatim}

\noindent 
Alternatively, the marginalization can be done for one or two
parameters individually: 
%
\begin{verbatim}
BCModel::MarginalizeProbability(BCParameter* parameter) ,
BCModel::MarginalizeProbability(char* name) , 
BCModel::MarginalizeProbability(BCParameter * parameter1, BCParameter * parameter2) ,
BCModel::MarginalizeProbability(char * name1, char * name2) .
\end{verbatim} 

\noindent 
Different methods of marginalization are implemented and can be chosen
via
%
\begin{verbatim}
BCModel::SetMarginalizationMethod(Model::BCMarginalizationMethod method)
\end{verbatim} 

\noindent
where \verb|BCMarginalizationMethod| can be one of the following 
% 
\begin{itemize}
\item \verb|BCModel::kMargMonteCarlo|. Uncorrelated Monte Carlo sampling.
\item \verb|BCModel::kMargMetropolis|. Correlated sampling using
  Markov Chain Monte Carlo (Metropolis algorithm).
\end{itemize} 

\noindent 
Note that only Markov chains can be used if the marginalization is
done for all parameters simultaneously. Settings and options of the
Markov Chain Monte Carlo algorithm are summarized in
section~\ref{section:settings:MCMC}. \\

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% -------------------------------------------------------- 

\subsection{Model comparison and hypothesis testing} 

% -------------------------------------------------------- 

\subsubsection{Model comparison}

Models $M_{i}$ can be compared by their posterior
probability. Technically, the models are added to a model manager and
given a prior probability (see
Section~\ref{subsection:modelmanager}). The posterior probability for
the $i$th model, given the data, is simply
%
\begin{equation}
p(\mathrm{M_{i}}|\mathrm{data}) = \frac{N_{\mathrm{i}} \cdot p_{0}(\mathrm{M_{i}})}{\sum_{\mathrm{j} = 1}^{N} N_{\mathrm{j}} \cdot p_{0}(\mathrm{M_{j}})} \, , 
\end{equation}
%
where $N_{i}$ is the normalization of the $i$th model posterior pdf
and $p_{0}(M_{i})$ is the prior probability for the $i$th model. The
posterior probability for a model can be evaluated once the model
manager is initialized and all numerical integrations are performed
via
%
\begin{verbatim}
BCModelManager::Normalize() . 
\end{verbatim}
%
The posterior probability can be returned from the model using the
following method:
%
\begin{verbatim}
double BCModel::GetModelAPosterioriProbability() . 
\end{verbatim}

Alternatively, Bayes factors can be calculated for two models using
%
\begin{verbatim}
double BayesFactor(const unsigned int imodel1, const unsigned int imodel2) \, ,
\end{verbatim} 
%
\noindent
where the arguments are the indices of the models in the model
manager. 


% --------------------------------------------------------

\subsubsection{Goodness-of-fit test} 

Once the most suitable set of parameters, $\vec{\lambda}^{*}$, for a
given model and data set, $D$, is estimated the appropriateness of the
model (and this choice of parameters) to describe the data can be
calculated. Data sets, $\{ \tilde{D} \}$, are generated under the
assumption of the model and the best-fit-parameters. A frequency
distribution $f$ of the obtained conditional probability
$k=p(\tilde{D}|\vec{\lambda}^{*})$ is calculated and interpreted as
probability density. The $p$-value is defined as the probability to
find a conditional probability $p(\tilde{D}|\vec{\lambda}^{*})$ equal
or less than that found for the original data set,
$k_{0}=p(D|\vec{\lambda}^{*})$, i.e.
%
\begin{equation}
p = \frac{1}{n} \int_{0}^{k_{0}=p(D|\vec{\lambda}^{*})} f(k) \, \mathrm{d}k \, . 
\end{equation} 

\noindent 
In the most general case, the $p$-value is calculated using Markov
Chain Monte Carlo. The calculation can be started by 
%
\begin{verbatim}
BCModel::CalculatePValue(std::vector<double> par, bool flag_histogram) ,
\end{verbatim}
%
\noindent 
where \verb|par| is a vector of the best-fit-parameters. The method
returns a pointer to a \verb|BCH1D| if the flag is set to true. The
$p$-value is calculated from this distribution and can be obtained by
%
\begin{verbatim}
double BCModel::GetPValue() . 
\end{verbatim} 

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% -------------------------------------------------------- 

\subsection{Fitting a function} 
\label{subsection:fitting}

A common application in data analysis is fitting a function, $y(x)$,
to a (one-dimensional) distribution or a set of data
points. \bat\ offers three dedicated tools for this purpose, depending
on the uncertainties on each data point. These classes and the assumed
uncertainties are summarized in the following. \\

\noindent 
In all three cases, the uncertainties for each data point (or bin
content) are assumed to be independent of each other. I.e., in the
case of histograms bin-by-bin migration is not included. The overall
conditional probability is a product of the individual probabilities
for the expectation value given the $y$-value (or bin content). \\

\noindent 
An uncertainty band is calculated for each fit. During the
marginalization, each point in parameter space is sampled with a
frequency proportional to the posterior pdf at this point (if the
Markov chain has converged). The uncertainty band is obtained by
evaluating the fit function, $y(x)$, for each $x$ at each point in
parameter space. The values are histogrammed in
$x$--$y(x)$--space. Each slice of $x$ is normalized to unity and
interpreted as probability density for $y$ given $x$. The~0.16 and
0.84~quantiles are then interpreted as the uncertainty on $y$ at that
particular $x$. The uncertainty band can be returned from a model using 
%
\begin{verbatim}
TGraph * BCModel::GetErrorBandGraph(double level1, double level2) ,  
\end{verbatim}
%
where the levels correspond to the quantiles of the distribution
$p(y(x))$ (default: 0.16 and 0.84). \\

\noindent 
In all three cases, the fast methods for evaluating the $p$-value are
implemented. The $p$-value is evaluated automatically and returned
together with a summary.

% --------------------------------------------------------

\subsubsection{The Gaussian case} 

The class \verb|BCGraphFitter| allows to fit a \Root\ function
(\verb|TF1|) to a \Root\ graph (\verb|TGraphErrors|). The
uncertainties on $y$ at a given $x$, defined by the uncertainties of
the \verb|TGraphErrors|, are assumed to be Gaussian, i.e., the
uncertainty on $y$ corresponds to the width, $\sigma$, of the
Gaussian. The uncertainties on $x$ are not taken into account.

% --------------------------------------------------------

\subsubsection{The Poissonian case} 

The class \verb|BCHistogramFitter| allows to fit a \Root\ function
(\verb|TF1|) to a \Root\ histogram (\verb|TH1D|). The uncertainty on
the expectation value in each bin is assumed to be Poissonian, and
thus non-symmetric around the number of entries in this bin.

% --------------------------------------------------------

\subsubsection{The Binomial case} 

The class \verb|BCEfficiencyFitter| allows to fit a \Root\ function
(\verb|TF1|) to the ratio of two \Root\ histograms (\verb|TH1D|). The
uncertainty on the expectation value in each bin is assumed to be
Binomial, and thus non-symmetric around the ratio of entries in this
bin. The ratio is assumed to be between 0 and 1, i.e., one histogram
contains a subset of the other.


% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% -------------------------------------------------------- 

\subsection{Propagation of uncertainties}

During the marginalization, each point in parameter space is sampled
with a frequency proportional to the posterior pdf at this point. It
is possible in \bat\ to calculate any (user-defined) function of the
parameters during the marginalization and thus obtain a frequency
distribution for the function value(s). This in turn can be
interpreted as the probability density for the function value(s). The
uncertainties on the parameters are thus propagated to the function
under study. An example for the propagation of uncertainties is the
calculation of the uncertainty band for the case of function fitting
(see Section~\ref{subsection:fitting}).  Uncertainty propagation can
be done by overloading the following method:
%
\begin{verbatim}
BCModel::MCMCUserIterationInterface() 
\end{verbatim}
%
which is called at every iteration during the main run of the MCMC.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% -------------------------------------------------------- 

\subsection{One- and two-dimensional histograms} 

The classes \verb|BCH1D| and \verb|BCH2D| are one- and two-dimensional
histogram classes which inherit from the \Root\-classes \verb|TH1D|
and \verb|TH2D|, respectively. They are filled, e.g., during
marginalization. Pointers to the \Root\ histograms can be returned
using
%
\begin{verbatim}
TH1D * BCH1D::GetHistogram() ,
TH2D * BCH2D::GetHistogram() .
\end{verbatim}
%
Once the histograms are filled summary information, such as the mean,
the mode and the median of the distribution, can be obtained by
%
\begin{verbatim}
BCH1D::GetMean() , 
BCH1D::GetMode() , 
BCH1D::GetMedian() . 
\end{verbatim} 
%
For one-dimensional histograms the quantiles of the distribution can
be returned using
%
\begin{verbatim}
double BCH1D::GetQuantile(double probablity) , 
\end{verbatim}
%
where \verb|probability| is a number between~0 and~1. This information
can be used to estimate uncertainties (e.g., the central 64\%
probability region) or limits on parameters (e.g., the quantile for
0.95). Alternatively, the smallest set of intervals containing a
certain probability can be obtained by 
%
\begin{verbatim}
void GetSmallestInterval(double & min, double & max, double content) . 
\end{verbatim}

\noindent 
Both types of histograms can be drawn to a \Root\ \verb|TCanvas| using
the methods
%
\begin{verbatim}
BCH1D::Draw(int options, double ovalue) , 
BCH2D::Draw(int options, bool drawmode) , 
\end{verbatim}  
%
where the options are summarized in Table~\ref{table:printingoptions}.

\begin{table}[ht!]
\begin{tabular}{ll}
\hline
Option & Style \\ 
\hline
BCH1D & \\ 
\hline 
0 (default) & \begin{minipage}[l]{12 cm}Draws a colored band at the central 68\% probability region. If the mode is not inside this band, the 95\% probabilty limit is drawn. \end{minipage}\\ 
1           & Draws a line at the value passed. \\ 
2           & Draws a colored band at the smallest interval containing \verb|ovalue|\% probability. \\
\hline 
BCH2D & \\ 
\hline 
0 (default) & Draw with the \Root\ option \verb|CONT0|. \\ 
1           & Draw the 68\%, 95\% and 99\% probability contours. \\ 
2           & Draw the 68\% probability contour. \\ 
3           & Draw the 90\% probability contour. \\ 
4           & Draw the 95\% probability contour. \\ 
\hline
\end{tabular}
\caption{Printing options for one- and two-dimensional histograms. 
\label{table:printingoptions}} 
\end{table}

% --------------------------------------------------------

%\subsection{Single event analyses and sensitivity studies}
%\label{subsection:singleeventanalyses}

%Often one is interested in repeating the same analysis on several data
%sets. This is particularly true for estimating the expected outcome of
%an analysis given a particular set of input parameters, e.g. to study
%the sensitivity of an experiment to a certain process. \bat\ offers an
%easy way to handle such processes and the outcome. \\ 

%\noindent 
%If a data set contains several data points and one data point
%describes the possible outcome of an experiment then one can use 
%%
%\begin{verbatim}
%BCModel::SetSingleDataPoint(BCDataPoint * datapoint) 
%BCModel::SetSingleDataPoint(BCDataSet * dataset, int index)  . 
%BCModelManager::SetSingleDataPoint(BCDataPoint * datapoint) 
%BCModelManager::SetSingleDataPoint(BCDataSet * dataset, int index)  . 
%\end{verbatim} 
%%
%The data set of the model (or model manager) will be set to a single
%event from the given data set. This allows to loop over the events of
%a data set without reloading and redefining it for each analysis. \\ 
%
%See \verb|example05| for an application of these features. 

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% output
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\section{Output}
\label{section:output}

\subsection{Log file}
\label{subsection:logfile}

The class \verb|BCLog| is used to write out information during the
runtime of the program. The output is written to screen and to a log
file. The minimum level of detail can be set independently for both
via
%
\begin{verbatim} 
void BCLog::SetMinimumLogLevelFile(BCLog::LogLevel loglevel) , 
void BCLog::SetMinimumLogLevelScreen(BCLog::LogLevel loglevel) , 
\end{verbatim} 
%
\noindent 
where the level is one of the following 
%
\begin{itemize} 
\item \verb|debug|: Lowest level of information. 
\item \verb|detail|: Details of functions, such as the status of the
  Markov chains, etc.
\item \verb|summary|: Results, such as best-fit values, normalization, etc. 
\item \verb|warning|: Warning messages 
\item \verb|nothing|: Nothing is written out. 
\end{itemize} 

A log file has to be opened in the beginning of the main file using
%
\begin{verbatim} 
void BCLog::OpenLog() . 
\end{verbatim} 

% -------------------------------------------------------- 
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% -------------------------------------------------------- 

\subsection{Summary information}

A summary of the MCMC run can be written to file or printed to the
screen using 
%
\begin{verbatim}
BCModel::PrintSummary(); 
BCModel::PrintSummary(const char * file); 
\end{verbatim}

The summary contains information about the convergence status, the
models, their parameters and respective ranges as well as information
about the marginalization (e.g., mean and rms, median and central 68\%
interval, and the smallest interval containing 68\% probability). The
results of the global maximization of the posterior probability is
also summarized.

% -------------------------------------------------------- 
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% -------------------------------------------------------- 

\subsection{Histograms}

Histograms of the marginalized distributions can be written to and
.eps file with the function
%
\begin{verbatim}
void PrintAllMarginalized(const char * file, int hdiv=1, int ndiv=1) ,
\end{verbatim}
%
\noindent 
where \verb|file| is the filename and \verb|hdiv| and \verb|ndiv|
define the number of divisions in the plots. Alternatively, the
histograms can be obtained from the model (see
section~\ref{subsubsection:marginalization}) and then plotted, printed
or stored in a \Root\ file.

% -------------------------------------------------------- 
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% -------------------------------------------------------- 

\subsection{The output class}

The results of an analysis can be stored in a \Root\ file using the
output class \verb|BCModelOutput|. This class is assigned a model
class and a file. It contains a \Root\ tree which stores the most
important information of the analysis outcome, such as the global
mode, the marginalized mode, means, limits, etc. The constructors are
%
\begin{verbatim}
BCModelOutput() 
BCModelOutput(BCModel * model, const char * filenname) .
\end{verbatim}
%
The model and filename can be set after construction using 
%
\begin{verbatim}
BCModelOutput::SetModel(BCModel * model) 
BCModelOutput::SetFile(const char * filename) . 
\end{verbatim}
%
The marginalized distributions can also be stored in the output file
using
%
\begin{verbatim}
BCModelOutput::WriteMarginalizedDistributions() . 
\end{verbatim}

The single points of the Markov Chain(s) can also be stored in the
output file together with the posterior probability at these
points. This can be done by setting a flag before the Markov Chain is
run:
%
\begin{verbatim}
BCModelOutput::WriteMarkovChain(bool flag = true) . 
\end{verbatim}
%
Please note that the file size can be large in case you chose this
options. Each chain is stored as a \Root\ tree. This option allows for
offline diagnostics of the chains. 

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% settings
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\section{Settings, options and special functions}
\label{section:settings}

% -------------------------------------------------------- 
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% -------------------------------------------------------- 

\subsection{Markov Chain settings and options}
\label{section:settings:MCMC} 

The most important options for the Markov Chains are listed here. For
further reference see the reference guide: 
%
\begin{itemize}
\item \verb|BCModel::SetNChains(int n)| Sets the number of chains
  which are ran in parallel (default: 5).
\item \verb|BCModel::MCMCSetNIterationsBurnIn(int n)| Sets the number
  of iterations of a burn-in run (default: 0). The burn-in run is
  performed before the pre-run.
\item \verb|BCModel::MCMCSetNIterationsMax(int n)| Sets the maximum
  number of iterations of the pre-run (default: 1,000,000).  
\item \verb|BCModel::MCMCSetNIterationsRun(int n)| Sets the number of
  iterations of the analysis run (default: 100,000). 
\item \verb|BCModel::MCMCSetNIterationsUpdate(int n)| Sets the number
  of iterations (default: 1,000) after which the chains are updated in
  the pre-run (e.g., for the calculation of the efficiency and
  convergence tests).
\item \verb|BCEngine::MCMCSetFlagOrderParameters(bool flag)|. Decides
  if all parameters should be varied one after each other (true) or
  all at the same time (default: true). 
\item \verb|BCModel::MCMCSetFlagInitialPosition(int flag)| Decides how
  to chose the initial positions (0: center of the parameter
  boundaries, 1: random positions (default), 2: user defined
  positions).
\item \verb|BCModel::MCMCSetFlagFillHistograms(int index, bool flag)| and \\ 
  \verb|BCModel::MCMCSetFlagFillHistograms(bool flag)|. Set flag to fill the marginalized distribution for a single or all parameters. Not filling the distributions might increase the speed of MCMC run. 
\item \verb|BCModel::MCMCSetInitialPositions(std::vector<double> x0s)|
  and \\ 
  \verb|MCMCSetInitialPositions(std::vector< std::vector<double> > x0s)|
  Set the initial positions of all parameters in all chains.
\item \verb|BCModel::MCMCSetMinimumEfficiency(double efficiency)| and \\ 
  \verb|MCMCSetMaximumEfficiency(double efficiency)|. Set the minimum
  (default: 15\%) and maximum (default: 50\%) efficiency of the Markov
  Chains. The efficiency found in the pre-run has to be within these
  limits otherwise the pre-run continues.
\item \verb|BCModel::MCMCSetRValueCriterion(double r)| Set the
  $r$-value criterion for convergence of a set of chains (default:
  0.1).
\end{itemize}

% -------------------------------------------------------- 
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% -------------------------------------------------------- 

\subsection{Setting and options for Simulated Annealing} 
\label{section:settings:SA} 

The most important options for the implemented Simulated Annealing
algorithm are listed here. For further reference see the reference
guide:
%
\begin{itemize}
\item \verb|BCModel::SetSASchedule(BCModel::BCSASchedule)|. Set the
  annealing schedule. This could be \verb|BCModel::kSACauchy|,
  \verb|BCModel::kSABoltzmann|, \verb|BCModel::kSACustom|. 
\item \verb|BCModel::SetSAT0(double T0)|. Set the starting
  temperature. 
\item \verb|BCModel::SetSATmin(double Tmin)|. Set the threshold
  temperature. 
\end{itemize}

% -------------------------------------------------------- 
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% -------------------------------------------------------- 

%\subsection{Special functions} 

% --------------------------------------------------------
% Technical tools 
% --------------------------------------------------------
%\section{Technical tools}
%\label{section:tools}

%{\it Save all this for a later version of the manual.} 

%\subsection{Optimization}

%\subsection{Markov Chain Monte Carlo}

%\subsection{Integration}

% --------------------------------------------------------
% More features
% --------------------------------------------------------
%\section{More features}
%\label{section:features}

%{\it Save all this for a later version of the manual.} 

%\subsection{Normalization}

%\subsection{Model comparison}

%\subsection{Fitting}

%\subsection{Single event analysis}

%\subsection{User defined data interface} 

% --------------------------------------------------------
% bibliography 
% --------------------------------------------------------

\addcontentsline{toc}{section}{Bibliography}

\begin{thebibliography}{99}
\bibitem{Caldwell:2008fw}
  A.~Caldwell, D.~Kollar and K.~Kroeninger,
  ``BAT - The Bayesian Analysis Toolkit,''
  arXiv:0808.2552 [physics.data-an].
%
\bibitem{ROOTweb}
http://root.cern.ch/
%
\bibitem{CUBA}
  T.~Hahn, ``CUBA: A library for multidimensional numerical
  integration,'' Comput.\ Phys.\ Commun.\ {\bf 168} (2005) 78
  [arXiv:hep-ph/0404043].
%
\bibitem{CUBAweb}
  http://www.feynarts.de/cuba/
\end{thebibliography}

% --------------------------------------------------------

\end{document} 


