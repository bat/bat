\documentclass[11pt, a4paper]{article}

%\usepackage{geometry}
%\usepackage{epsfig}
%\usepackage{epstopdf}
%\usepackage{graphics}
\usepackage{graphicx}
\usepackage{url}

\setlength{\oddsidemargin}{0cm}
\setlength{\evensidemargin}{0cm}
\setlength{\topmargin}{-1cm}
\setlength{\textheight}{23cm}
\setlength{\textwidth}{16cm}

\pagestyle{headings}

\newcommand{\bat}{{\sc BAT}}
\newcommand{\Root}{{\sc Root}}
\newcommand{\versionno}{0.4}
\newcommand{\version}{version~\versionno}
\newcommand{\Version}{Version~\versionno}

%--------------------------------------------------------

\begin{document}

% --------------------------------------------------------
% title
% --------------------------------------------------------

\thispagestyle{empty}

\begin{figure}
\includegraphics[scale=0.25]{bat.eps}
\end{figure}

\vspace*{1cm}

\begin{center}


{\Large A short introduction to \bat}
\\

\vspace{1cm}

{\large \bat\ \version}

\end{center}

\thispagestyle{empty}

\vfill

\begin{center}
\today
\end{center}

\pagebreak

% --------------------------------------------------------
% table of contents
% --------------------------------------------------------

\thispagestyle{empty}

\enlargethispage{2cm}

\tableofcontents

\pagebreak

% --------------------------------------------------------
% introduction
% --------------------------------------------------------
\section{Introduction}
\label{section:introduction}

The Bayesian Analysis Toolkit, \bat, is a software package designed to
help solve statistical problems encountered in Bayesian
inference. Allowing to formulate models and their parameters, the main
purpose of the toolkit is to provide methods to solve the numerical
optimization and integration. It features the possibility to estimate
parameters and to compare models. A procedure to estimate the
goodness-of-fit is included and based on ensemble tests. A detailed
introduction to \bat\ can be found in~\cite{Caldwell:2008fw}.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% installation
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\section{Installation}
\label{section:installation}

\subsection{Availability}

\bat\ can be downloaded from \url{http://www.mppmu.mpg.de/bat}.

\bigskip

\noindent
\bat\ is a free software: you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License (LGPL) as
published by the Free Software Foundation, either version 3 of
the License, or any later version.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Platforms}

\bat\ has been developed on Linux machines running different distributions
and different versions of the kernel and gcc. As far as we know there
is nothing distribution dependent inside of \bat. However, we have not
yet started to systematically check for compatibility and
portability. This is planned for future releases of \bat. For the
moment the only statement we can do here is that if you don't have a
too old or too specific installation of Linux you should be able to
compile and use \bat\ without problems. \\

\noindent
The installation and functionality of BAT has also been tested on MACs. \\

\noindent
Windows is not supported for the moment.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Dependencies}

\subsubsection{\Root}
\Root\ is an object oriented data analysis framework. You can obtain it
from~\cite{ROOTweb}. To compile and run \bat\ you will need a \Root\
version 5.16 or later. Please, check your Linux distribution for the
availability of precompiled packages on your system. Mostly used
distributions nowadays have the \Root\ packages available. \\

\noindent
Note: To be able to use the interface to {\sc RooFit/RooStats} the \Root\
version 5.24 or later is necessary.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Recommendations}

\enlargethispage{1cm}

\paragraph{CUBA:}
CUBA~\cite{CUBA} is a library containing general purpose
multidimensional integration algorithms. It can be obtained
from~\cite{CUBAweb}. In this version \bat\ no longer depends on CUBA
and you can compile and run without it. However, the use of CUBA is
recommended as it provides integration routines tuned for performance,
which are very useful for integration in problems with large number
of dimensions. \\

\noindent
Note: Since version 1.5 the compilation of CUBA no longer crashes if
you don't have Mathematica installed. To compile and install CUBA
libraries use commands ~\verb|make lib;| ~\verb|make install|.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Installation procedure}

Unpack the tarball containing the \bat\ source usually named like
\verb|BAT-x.x.tar.gz| (here x.x is the version number) using command
%
\begin{verbatim}
tar -xzf BAT-x.x.tar.gz
\end{verbatim}
%
A directory called \verb|BAT-x.x| will be created containing the source code.
Enter the directory and run the configuration using commands
%
\begin{verbatim}
cd BAT-x.x
./configure
\end{verbatim}

\noindent 
This will check your system for all components needed to compile \bat\
and set up the paths for installation. You can add option
\verb|--prefix=/path/to/install/bat| to \verb|./configure| to specify
the the prefix to the \bat\ installation path. The \bat\ library files
will be installed to \verb|$prefix/lib| and the include files to
\verb|$prefix/include|. Default installation prefix is
\verb|/usr/local|. \\

\noindent
The configure script checks for \Root\ availability in the system and
fails if \Root\ is not installed. You can specify the ROOTSYS directory
using \verb|--rootsys=/path/to/rootsys|. \\

\noindent
The configure will also search for \verb|libcuba.a| and \verb|cuba.h|
in the system.  The \verb|libcuba.a| has to be available in the
standard system library search path. You can specify the \verb|cuba.h|
location using \verb|--with-cuba-path=/path/to/cuba/header|. \\

\enlargethispage{1cm}

\noindent
After successful configuration run
%
\begin{verbatim}
make
make install
\end{verbatim}
%
to compile and install \bat. Note that depending on the setting of
installation prefix you might need root privileges to be able to
install \bat. If you are installing \bat\ e.g. in your
\verb|$HOMEDIR|, %$ workaround for bad highlighting you need to add
the path to the library and to the include files to the search path in
your system. Depending on your shell you can do that via commands
%
\begin{verbatim}
export BATINSTALLDIR=/bat/install/prefix
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$BATINSTALLDIR/lib
export CPATH=$CPATH:$BATINSTALLDIR/include
\end{verbatim}
%
or
%
\begin{verbatim}
setenv BATINSTALLDIR    /bat/install/prefix
setenv LD_LIBRARY_PATH  $LD_LIBRARY_PATH:$BATINSTALLDIR/lib
setenv CPATH            $PATH:$BATINSTALLDIR/include
\end{verbatim}
%
for \verb|bash| and \verb|csh| compatible shells, respectively. \\

\noindent
An option for use in compiled programs would also be to add
\verb|-I/bat/install/include/path| to \verb|CFLAGS| and
\verb|-L/bat/install/lib/path| to \verb|LDFLAGS| in your
\verb|Makefile|. However, the interactive \Root\ macros will not work if
\verb|libBAT.so| and \verb|libBAT.rootmap| both aren't in the system
library search path. \\

\noindent
See also \verb|doc/INSTALL| for installation instructions.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% analysis chain
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

%\pagebreak

\section{Running \bat}
\label{section:running}

\subsection{The analysis chain}
\label{subsection:chain}

The typical analysis chain in \bat\ is the following: one or several
models are defined together with their parameters and corresponding
ranges. Data is read in from a file and interfaced with each
model. For each model parameters are estimated either from the
posterior probability density or from the marginalized probability
densities of the individual parameters. Models can be compared using
direct probabilities or Bayes factors. A goodness--of--fit test can be
performed by evaluating the likelihood for an ensemble of possible
data sets given the best-fit parameters. The data sets are generated
under the assumption of the model at hand and the best-fit
parameters. \\

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Getting started}
\label{subsection:start}

\bat\ comes in form of a library. It can be linked against in any
existing C++ code, or it can be used in an interactive
\Root\ session. The latter case is discussed later on in this
manual. Several files need to be provided by the user in order to
start a new project:
%
\begin{itemize}
\item A makefile in which the \bat\ library is linked.
\item Include and source files of the classes defining the models
used in the analysis (see next section).
\item A main file in which the actual analysis is performed.
\end{itemize}
%
The script \verb|BAT/tools/CreateProject.sh| can be used to create an
empty analysis skeleton including the above listed files.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Creating a model}
\label{subsection:model}

% --------------------------------------------------------

\subsubsection{Implementation of a mathematical model as a C++ class}
\label{subsubsection:implementation}

The mathematical models used in \bat\ are implemented in terms of C++
classes. All model classes inherit from the class \verb|BCModel|. This
base class has several public member functions which need to be
overloaded by the user in order to specify the mathematical
expressions for an unambiguous definition of the model. Apart from the
constructor and destructor, these methods are
%
\begin{itemize}
\item \verb|void BCModel::DefineParameters()| \\
This method has to be called at construction and contains the
definition of parameters.
%
\item
  \verb|double BCModel::LogLikelihood(std::vector <double> parameters)|
  \\ This method contains a mathematical expression for the
  conditional probability of the data given a set of parameter values,
  $p(x|\vec{\lambda})$. It returns the logarithm of the conditional
  probability for reasons of numerical stability.
%
\item
  \verb|double BCModel::LogAPrioriProbability(std::vector <double> parameters)|
  \\ This method contains a mathematical expression for the {\it a
    priori} probability for a set of parameter values. It returns the
  logarithm of the conditional probability for reasons of numerical
  stability.
\end{itemize}

\noindent
A class derived from \verb|BCModel| can contain any number of
additional member functions. \\

\noindent
If the parameters are considered independent in the prior probability,
then
%
\begin{verbatim}
BCModel::LogAPrioriProbability(std::vector <double> parameters)
\end{verbatim}
%
need not be overloaded.  Alternatively, they can be set for individual
parameters through \verb|TF1| function objects using
%
\begin{verbatim}
int BCModel::SetPrior(int index, TF1 * f)
\end{verbatim}
%
For ease of use, frequently used priors are predefined.
%
\begin{verbatim}
int SetPriorGauss(int index, double mean, double sigma);
int SetPriorGauss(int index, double mean, double sigmadown, double sigmaup);
\end{verbatim}
%
The prior maybe chosen constant over one or all dimensions of the
parameter space using
%
\begin{verbatim}
int SetPriorConstant(int index);
int SetPriorConstantAll();
\end{verbatim}
%
Note that the correct constant is calculated from the parameter ranges
only once, and then cached for reuse during the Markov chain run. For
simple problems, caching can significantly speed up the execution,
while for complicated likelihoods, the time spent calculating the
prior probability is usually negligible. \\

\noindent 
In case the prior is undefined for one of the parameters, a constant
prior for that parameter is assumed, and a warning is issued.

% --------------------------------------------------------

\subsubsection{Definition of parameters of a model}
\label{subsubsection:parameters}

The parameters of a model are implemented as a C++ class named
\verb|BCModelParameter|. They can be interfaced to a model in two
ways: parameters can be defined explicitly and then added to a model
via
%
\begin{verbatim}
BCParameter * parameter = new BCParameter(const char* name,
                                          double lowerlimit, double upperlimit);
BCModel::AddParameter(BCParameter * parameter),
\end{verbatim}

\noindent
where the arguments in the first case are the name of the parameter,
and the lower and upper limit of the parameter,
respectively. Parameters can also be defined implicitly via
%
\begin{verbatim}
BCModel::AddParameter(const char* name, double lowerlimit, double upperlimit) .
\end{verbatim}

\noindent
Every parameter has to have a unique name and valid limits. Once added
to a model each parameter is given a unique index starting at zero. A
parameter can be referenced to by its index or by its name. It can be
returned from a model using the methods
%
\begin{verbatim}
BCModel::GetParameter(int index),
BCModel::GetParameter(char* name).
\end{verbatim}

\noindent
It is possible to change the lower and upper limit of a parameter
after it has been added to the model: 
%
\begin{verbatim}
BCModel::SetParameterRange(int index, double parmin, double parmax) .
\end{verbatim}
%
A call to this method resets all results obtained so far since the
model has changed. 

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Data}
\label{subsection:data}

\subsection{Data format and handling}
\label{subsection:dataformat}

Data is managed in the form of data points which are combined to data
sets. Data points and sets are implemented as classes
\verb|BCDataPoint| and \verb|BCDataSet|, respectively. \\

\noindent
The class \verb|BCDataPoint| contains a set of double precision
values. Data points can be generated explicitly by the user with or
without initial value
%
\begin{verbatim}
BCDataPoint::BCDataPoint(int nvariables) ,
BCDataPoint::BCDataPoint(vector<double> x) .
\end{verbatim}

\noindent
Values of a data point can either be set value-by-value or for all
values at once
%
\begin{verbatim}
BCDataPoint::SetValue(int index, double value) ,
BCDataPoint::SetValues(std::vector <double> values) .
\end{verbatim}

\noindent
The value of the $i$th entry can be obtained by
%
\begin{verbatim}
BCDataPoint::GetValue(int index) .
\end{verbatim}

\noindent
A data point can be added to a data set with the method

\begin{verbatim}
BCDataSet::AddDataPoint(BCDataPoint* datapoint) .
\end{verbatim}

\noindent
Alternatively, data can be read in from a file
%
\begin{verbatim}
BCDataSet::ReadDataFromFile(char* filename,
													  char* treename, const char* branchnames) ,
BCDataSet::ReadDataFromFile(char* filename, int nvariables) .
\end{verbatim}

\noindent
The data format for ASCII files is such that each data point
corresponds to one line, each containing several values. Note that the
number of values per data point has to be provided by the user. \\

\noindent
Once a data set is defined it can be assigned to a model with
%
\begin{verbatim}
BCModel::SetDataSet(BCDataSet* dataset) .
\end{verbatim}

\noindent
Similarly, a data set can be returned from a model with
%
\begin{verbatim}
BCModel::GetDataSet() .
\end{verbatim}

\noindent
Note that the user can define several data sets. However, a model can
only have one data set at a time. This data set can be accessed in the
overloaded method \verb|BCModel::LogLikelihood()|.

% --------------------------------------------------------

\subsubsection{Constraining the values of data points}

For two applications discussed later in this section, the
goodness-of-fit test and the calculation of error bands, it is
necessary to define the limits of the data points. This is done for
each variable separately. Note that the limits are defined by the
model, not by the data set:
%
\begin{verbatim}
BCModel::SetDataBoundaries(int index, double lowerboundary,
													 double upperboundary) .
\end{verbatim}

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Managing more than one model: the model manager}
\label{subsection:modelmanager}

In case more than one model is defined and all models use the same
data set a model manager can be defined. It is implemented as a class
named \verb|BCModelManager|. Models and their (model) prior
probability are added to the model manager via
%
\begin{verbatim}
BCModelManager::AddModel(BCModel * model, double probability) ,
BCModelManager::AddModel(BCModel * model) ,
\end{verbatim}

\noindent
where \verb|probability| is the prior probability for the model. A
common data set can be defined and will be patched through to all
models added to the manager class. This can either be done explicitly
via
%
\begin{verbatim}
BCModelManager::SetDataSet(BCDataSet * dataset) ,
\end{verbatim}

\noindent
or by reading data from a file via
%
\begin{verbatim}
BCModelManager::ReadDataFromFile(char* filename, char* treename,
																 const char* branchnames) ,
BCModelManager::ReadDataFromFile(char* filename, int nvariables) .
\end{verbatim}

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Normalization and numerical integration}
\label{section:normalization}

The posterior pdf is normalized to unity in Bayes' Theorem. The
normalization is an integral of the conditional probability times the
prior probability over the whole parameter range. Since the analytical
form of the integral is not known in general this integral is solved
numerically. Several methods for numerical integration are implemented
in the package and can be chosen by
%
\begin{verbatim}
BCModel::SetIntegrationMethod(BCModel::BCIntegrationType method),
\end{verbatim}

\noindent
where \verb|BCIntegrationType| can be one of the following
%
\begin{itemize}
\item \verb|BCModel::kIntMonteCarlo|. A sampled mean integration.
\item \verb|BCModel::kIntImportance|. A sampled mean integration
 with importance sampling.
\item \verb|BCModel::kIntMetropolis|. A sampled mean integration
 with importance sampling using Markov chains.
\item \verb|BCModel::kIntCuba|. An interface to the CUBA
  library~\cite{CUBA,CUBAweb}.
\end{itemize}

\noindent
The normalization can be performed for each model separately or for
all models which belong to a model manager:
%
\begin{verbatim}
BCModel::Normalize() ,
BCModelManager::Normalize() .
\end{verbatim}

\noindent
The normalization is stored for each model. The value can be obtained
by
%
\begin{verbatim}
double BCModel::GetNormalization() .
\end{verbatim}

\noindent
Once the integral is calculated the posterior pdf for a set of
parameter values can be evaluated
%
\begin{verbatim}
BCModel::Probability(std::vector <double> parameter) ,
BCModel::LogProbability(std::vector <double> parameter) ,
\end{verbatim}
%
where the latter returns the logarithm of the posterior pdf.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Parameter estimation and marginalization}

The posterior pdf can be used to estimate the set of parameter values
most suited to describe the data. This is done by searching for the
most probable value, or mode, of the posterior pdf. Two approaches are
followed: either the mode in the whole parameter space is searched
for, or the pdf is marginalized with respect to the particular
parameter under study. In the latter case, several quantities can used
to describe the marginalized distributions.

% --------------------------------------------------------

\subsubsection{Maximization of the full posterior probability density}

The maximization of the full posterior pdf can be performed using the
method
%
\begin{verbatim}
BCModel::FindMode() .
\end{verbatim}

\noindent
The vector of parameter values which maximizes the posterior pdf can be obtained using
%
\begin{verbatim}
std::vector <double> BCModel::GetBestFitParameters() ,
double BCModel::GetBestFitParameter(unsigned int index) .
\end{verbatim}
%
The implemented algorithms can be chosen with the command
%
\begin{verbatim}
BCModel::SetOptimizationMethod(BCIntegrate::BCOptimization method) .
\end{verbatim}
%
Three methods are available in the current version (\Version):
%
\begin{itemize}
\item \verb|BCModel::kOptMetropolis|. A sampling algorithm using the
  Metropolis algorithm.
\item \verb|BCModel::kOptMinuit|. An interface to the \Root\ version
  of Minuit.
\item \verb|BCModel::kOptSA|. A Simulated Annealing algorithm.
\end{itemize}
%
If the interface to Minuit is used the estimated uncertainties on the
parameters can be obtained using
%
\begin{verbatim}
std::vector <double> BCModel::GetBestFitParameterErrors() ,
double BCModel::GetBestFitParameterError(unsigned int index) .
\end{verbatim}
%
Settings and options of the Simulated Annealing algorithm are
summarized in section~\ref{section:settings:SA}. \\

\noindent 
If several algorithms are ran one after the other, a flag controls
whether to ignore the results from a previous maximization:
%
\begin{verbatim}
BCModel::SetFlagIgnorePrevOptimization(bool flag) .
\end{verbatim}

% --------------------------------------------------------

\subsubsection{Marginalization}
\label{subsubsection:marginalization}

\noindent
The single parameter estimation is done via marginalization. If more
than one parameter is studied it is most efficient to marginalize with
respect to all parameters simultaneously. This can be done using
%
\begin{verbatim}
BCModel::MarginalizeAll() .
\end{verbatim}

\noindent
One- and two-dimensional histograms are filled during the
marginalization. They can be accessed by
%
\begin{verbatim}
BCModel::GetMarginalized(BCParameter * parameter) ,
BCModel::GetMarginalized(char * name) ,
BCModel::GetMarginalized(BCParameter * parameter1, BCParameter * parameter2) ,
BCModel::GetMarginalized(char * name1, char * name2) .
\end{verbatim}

\noindent
Alternatively, the marginalization can be done for one or two
parameters individually:
%
\begin{verbatim}
BCModel::MarginalizeProbability(BCParameter* parameter) ,
BCModel::MarginalizeProbability(char* name) ,
BCModel::MarginalizeProbability(BCParameter * parameter1, BCParameter * parameter2) ,
BCModel::MarginalizeProbability(char * name1, char * name2) .
\end{verbatim}

\noindent
Different methods of marginalization are implemented and can be chosen
via
%
\begin{verbatim}
BCModel::SetMarginalizationMethod(Model::BCMarginalizationMethod method)
\end{verbatim}

\noindent
where \verb|BCMarginalizationMethod| can be one of the following
%
\begin{itemize}
\item \verb|BCModel::kMargMonteCarlo|. Uncorrelated Monte Carlo sampling.
\item \verb|BCModel::kMargMetropolis|. Correlated sampling using
  Markov Chain Monte Carlo (Metropolis algorithm).
\end{itemize}

\noindent
Note that only Markov chains can be used if the marginalization is
done for all parameters simultaneously. Settings and options of the
Markov Chain Monte Carlo algorithm are summarized in
section~\ref{section:settings:MCMC}. \\

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Model comparison and hypothesis testing}

% --------------------------------------------------------

\subsubsection{Model comparison}

Models $M_{i}$ can be compared by their posterior
probability. Technically, the models are added to a model manager and
given a prior probability (see
Section~\ref{subsection:modelmanager}). The posterior probability for
the $i$th model, given the data, is simply
%
\begin{equation}
p(\mathrm{M_{i}}|\mathrm{data}) = \frac{N_{\mathrm{i}} \cdot p_{0}(\mathrm{M_{i}})}{\sum_{\mathrm{j} = 1}^{N} N_{\mathrm{j}} \cdot p_{0}(\mathrm{M_{j}})} \, ,
\end{equation}
%
where $N_{i}$ is the normalization of the $i$th model posterior pdf
and $p_{0}(M_{i})$ is the prior probability for the $i$th model. The
posterior probability for a model can be evaluated once the model
manager is initialized and all numerical integrations are performed
via
%
\begin{verbatim}
BCModelManager::Normalize() .
\end{verbatim}
%
The posterior probability can be returned from the model using the
following method:
%
\begin{verbatim}
double BCModel::GetModelAPosterioriProbability() .
\end{verbatim}

\noindent 
Alternatively, Bayes factors can be calculated for two models using
%
\begin{verbatim}
double BayesFactor(const unsigned int imodel1, const unsigned int imodel2) ,
\end{verbatim}
%
\noindent
where the arguments are the indices of the models in the model
manager.


% --------------------------------------------------------

\subsubsection{Goodness-of-fit test}

Once the most suitable set of parameters, $\vec{\lambda}^{*}$, for a
given model and data set, $D$, is estimated the appropriateness of the
model (and this choice of parameters) to describe the data can be
calculated. Data sets, $\{ \tilde{D} \}$, are generated under the
assumption of the model and the best-fit-parameters. A frequency
distribution $f$ of the obtained conditional probability
$k=p(\tilde{D}|\vec{\lambda}^{*})$ is calculated and interpreted as
probability density. The $p$-value is defined as the probability to
find a conditional probability $p(\tilde{D}|\vec{\lambda}^{*})$ equal
or less than that found for the original data set,
$k_{0}=p(D|\vec{\lambda}^{*})$, i.e.
%
\begin{equation}
p = \frac{1}{n} \int_{0}^{k_{0}=p(D|\vec{\lambda}^{*})} f(k) \, \mathrm{d}k \, .
\end{equation}

\noindent
In the most general case, the $p$-value is calculated using Markov
Chain Monte Carlo. The dimension of the sampled space is the number
of datapoints. 
 The calculation can be started by
%
\begin{verbatim}
BCModel::CalculatePValue(std::vector<double> par, bool flag_histogram) ,
\end{verbatim}
%
\noindent
where \verb|par| is a vector of the best-fit-parameters. The method
returns a pointer to a \verb|BCH1D| if the flag is set to true. The
$p$-value is calculated from this distribution and can be obtained by
%
\begin{verbatim}
double BCModel::GetPValue() .
\end{verbatim}

\noindent
For a number of models the distribution of test certain statistics is
approximately known. Hence the CPU intensive generation of data sets
can be avoided, and the $p$-value is computed much faster. \\

\noindent 
If the total probability of the data $p\left(D|\vec{\lambda}^{*}\right)$
 factorizes into $N$ independent observations 
$$p\left(D|\vec{\lambda}^{*}\right) = \prod_{i=1}^N
p_i\left(y_i|\vec{\lambda}^{*}\right)$$ and the cumulative
distribution functions (CDF) $F_i(y)= \int_{-\infty}^{y}
p_i(y'|\vec{\lambda}^{*}) \mathrm{d }y'$ are known, the $\chi^2$ test
statistic described by Johnson \cite{Johnson_pValue} can be computed.
Asymptotically (i.e. for many observations) it has $N-1$ degrees of
freedom for any parameter $\lambda$ drawn from the posterior. Note
that this implies that for bad models and small $N$, one occasionally
obtains a moderate $p$-value although $p\approx 0 $ is expected. This
is especially so for discrete probability models. For those to work
correctly, the \texttt{BCModel} property \verb|flag_discrete| has to
be set to to \texttt{true} (default is \texttt{false}).  To enable the
calculation, \verb|BCModels| method
%
\begin{verbatim}
virtual double CDF(const std::vector<double>& par, int index, bool lower=false)
\end{verbatim}
%
has to be overridden in the user model.  \verb|int index| defines the
single data point in the data set. The flag \verb|bool lower| is only
needed for models with discrete probabilities (e.g. Poisson) as
opposed to continuous probability densities (e.g. Gaussian). It
controls whether the CDF is computed not for the actual observation,
but for the hypothetical one with a value just one quantum lower. An
example to clarify this: if in a Poisson process, for bin $2$ a count
of $4$ has been observed, $n_2=4$, then the next lower value is
$n_2=3$.  With the CDF defined, the $p$-value is returned from
\begin{verbatim}
double BCModel::GetPvalueFromChi2Johnson(std::vector<double> par)
\end{verbatim}

\noindent 
For \textit{Gaussian} problems (handled by the model
\verb|BCGraphFitter|, sec. \ref{BCGraphFitter}) the standard $\chi^2$
statistic can be used, including the correction for the number of
fitted parameters, from
%
\begin{verbatim}
double BCModel::GetPvalueFromChi2NDoF(std::vector<double> par, int sigma_index)
\end{verbatim}
%
where \verb|sigma_index| is the index of the standard deviation in
each data point. \\

\noindent
In the \textit{Poisson} case (described by the model \verb|BCHistogramFitter|) has three
specific choices to obtain a $p$-value: 
\begin{enumerate}
 \item 
\begin{verbatim}
int CalculatePValueFast(std::vector<double> par, double &pvalue)
\end{verbatim}
which uses a discrete Markov chain to vary the bin counts. 
The conditional probability $k$ is then recomputed, and
again the proportion of datasets with lower $k$ is
reported as the $p$-value. 
\item
\begin{verbatim}
int CalculatePValueLikelihood(std::vector<double> par, double &pvalue)
\end{verbatim}
uses the fact that the rescaled likelihood ratio defined in
Eq. (32.12) of \cite{PDGstatistics} has an approximate
$\chi^2$-distribution if all the bin counts aren't too small,
i.e. $n_i \ge 5$.

\item
\begin{verbatim}
int CalculatePValueLeastSquares(std::vector<double> par,
                               double &pvalue, bool weightExpect=true)
\end{verbatim}
calculates the sum of squared differences between observed counts and
expected counts, $$\chi^2 = \sum_{i=1}^N \frac{\left(n_i -
\nu_i(\lambda^{*})\right)^2}{\sigma_i^2},$$ where the weights
$\sigma_i$ can be chosen as the expectation values from the Poisson
distribution $\sigma_i^2 = \nu_i$ (\verb|weightExpect=true|) or as the
observed counts, $\sigma_i^2 = n_i$ (\verb|weightExpect=false|).  The
latter choice is especially problematic for no observed count, $n_i
=0$. In that case the weight is arbitrarily set to unity.  $\chi^2$
has an approximate $\chi^2$-distribution with $N-dim(\lambda)$ degrees
of freedom for $n_i>5$.
\end{enumerate}
In all three methods the return value is an integer error code, and
the resulting $p$-value is stored in the reference
\verb|double &pvalue|.  Additionally the cumulative distribution
function is implemented so the $p$-value due to Johnson
\cite{Johnson_pValue} can be obtained directly by calling
\begin{verbatim}
double BCHistogramFitter::GetPvalueFromChi2Johnson(std::vector<double> par)
\end{verbatim}

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Propagation of uncertainties}

During the marginalization, each point in parameter space is sampled
with a frequency proportional to the posterior pdf at this point. It
is possible in \bat\ to calculate any (user-defined) function of the
parameters during the marginalization and thus obtain a frequency
distribution for the function value(s). This in turn can be
interpreted as the probability density for the function value(s). The
uncertainties on the parameters are thus propagated to the function
under study. An example for the propagation of uncertainties is the
calculation of the uncertainty band for the case of function fitting
(see Section~\ref{subsection:fitting}).  Uncertainty propagation can
be done by overloading the following method:
%
\begin{verbatim}
BCModel::MCMCUserIterationInterface()
\end{verbatim}
%
which is called at every iteration during the main run of the
MCMC. The user has to loop over all chains and parameters using the
private variable \verb|fMCMCx| which is a vector of double values with
a length of the number of chains times the number of parameters. An
example code is given here which calculates a radius in 3D for each
iteration (and chain) and fills it into a histogram:

\begin{verbatim}
void MyModel::MCMCIterationInterface()
{
  // get number of chains
  int nchains = MCMCGetNChains();

  // get number of parameters
  int npar = GetNParameters();

  // loop over all chains and fill histogram
  for (int i = 0; i < nchains; ++i) {
    // get the current values of the parameters x, y, z. These are
    // stored in fMCMCx.
    double x = fMCMCx.at(i * npar + 0); // parameter with index 0 in chain i
    double y = fMCMCx.at(i * npar + 1); // parameter with index 1 in chain i
    double z = fMCMCx.at(i * npar + 2); // parameter with index 2 in chain i

    // calculate the radius
    double r = sqrt(x*x + y*y + z*z); 

    // fill the histogram
    myHistogramR->Fill(r);
  }
}
\end{verbatim}

\noindent 
An example for the propagation of uncertainties can be found in
\linebreak \verb|examples/basic/errorpropagation|. 

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{One- and two-dimensional histograms}

The classes \verb|BCH1D| and \verb|BCH2D| are one- and two-dimensional
histogram classes which inherit from the \Root\-classes \verb|TH1D|
and \verb|TH2D|, respectively. They are filled, e.g., during
marginalization. Pointers to the \Root\ histograms can be returned
using
%
\begin{verbatim}
TH1D * BCH1D::GetHistogram() ,
TH2D * BCH2D::GetHistogram() .
\end{verbatim}
%
Once the histograms are filled summary information, such as the mean,
the mode and the median of the distribution, can be obtained by
%
\begin{verbatim}
BCH1D::GetMean() ,
BCH1D::GetMode() ,
BCH1D::GetMedian() .
\end{verbatim}
%
For one-dimensional histograms the quantiles of the distribution can
be returned using
%
\begin{verbatim}
double BCH1D::GetQuantile(double probability) ,
\end{verbatim}
%
where \verb|probability| is a number between~0 and~1. This information
can be used to estimate uncertainties (e.g., the central 64\%
probability region) or limits on parameters (e.g., the quantile for
0.95). Alternatively, the smallest set of intervals containing a
certain probability can be obtained by
%
\begin{verbatim}
void GetSmallestInterval(double & min, double & max, double content) .
\end{verbatim}

\noindent
Both types of histograms can be drawn to a \Root\ \verb|TCanvas| using
the methods
%
\begin{verbatim}
BCH1D::Draw(int options, double ovalue) ,
BCH2D::Draw(int options, bool drawmode) ,
\end{verbatim}
%
where the options are summarized in Table~\ref{table:printingoptions}.

\begin{table}[ht!]
\begin{tabular}{ll}
\hline
Option & Style \\
\hline
BCH1D & \\
\hline
0 (default) & \begin{minipage}[l]{12 cm}Draws a colored band at the central 68\% probability region. If the mode is not inside this band, the 95\% probability limit is drawn. \end{minipage}\\
1           & Draws a line at the value passed. \\
2           & Draws a colored band at the smallest interval containing \verb|ovalue|\% probability. \\
\hline
BCH2D & \\
\hline
0 (default) & Draw with the \Root\ option \verb|CONT0|. \\
1           & Draw the 68\%, 95\% and 99\% probability contours. \\
2           & Draw the 68\% probability contour. \\
3           & Draw the 90\% probability contour. \\
4           & Draw the 95\% probability contour. \\
\hline
\end{tabular}
\caption{Printing options for one- and two-dimensional histograms.
\label{table:printingoptions}}
\end{table}

% --------------------------------------------------------

%\subsection{Single event analyses and sensitivity studies}
%\label{subsection:singleeventanalyses}

%Often one is interested in repeating the same analysis on several data
%sets. This is particularly true for estimating the expected outcome of
%an analysis given a particular set of input parameters, e.g. to study
%the sensitivity of an experiment to a certain process. \bat\ offers an
%easy way to handle such processes and the outcome. \\

%\noindent
%If a data set contains several data points and one data point
%describes the possible outcome of an experiment then one can use
%%
%\begin{verbatim}
%BCModel::SetSingleDataPoint(BCDataPoint * datapoint)
%BCModel::SetSingleDataPoint(BCDataSet * dataset, int index)  .
%BCModelManager::SetSingleDataPoint(BCDataPoint * datapoint)
%BCModelManager::SetSingleDataPoint(BCDataSet * dataset, int index)  .
%\end{verbatim}
%%
%The data set of the model (or model manager) will be set to a single
%event from the given data set. This allows to loop over the events of
%a data set without reloading and redefining it for each analysis. \\
%
%See \verb|example05| for an application of these features.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% Tools and models
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\clearpage
\pagebreak

\section{Tools and models}
\label{section:tools}

\subsection{Tools}
\label{subsection:tools}

\subsubsection{The summary tool}

A summary tool, \verb|BCSummaryTool|, is provided with BAT which
summarizes the results of the marginalization. It creates a set of
plots and tables. An instance of the class can be created by
%
\begin{verbatim}
BCSummaryTool() ,
BCSummaryTool(BCModel * model);
\end{verbatim}
%
If the model is not set during construction it can be set using the
method
%
\begin{verbatim}
void SetModel(BCModel * model) .
\end{verbatim}

\noindent
After the marginalization of the posterior has been performed, a
set of plots can be produced with the following methods:
%
\begin{itemize}
\item \verb|BCSummaryTool::PrintParameterPlot|. Creates an overview
plots of the marginalized mode, standard deviation, the most important
quantiles and the global mode for all parameters.
\item \verb|PrintCorrelationPlot|. Prints a two-dimensional
correlation matrix of the parameters.
\item \verb|PrintKnowlegdeUpdatePlot|. Prints the marginalized
distributions for the prior and posterior probablity. This illustrates
the update in knowledge due to the data. Calling this function will
re-run the analysis without the use of the \verb|LogLikelihood|
information.
\end{itemize}

\noindent
In addition, a latex table of the parameters and the results can be
produced with the method:
%
\begin{verbatim}
PrintParameterLatex(const char * filename) .
\end{verbatim}

\subsection{Models for function fitting}
\label{subsection:fitting}

A common application in data analysis is fitting a function, $y(x)$,
to a (one-dimensional) distribution or a set of data
points. \bat\ offers three dedicated tools for this purpose, depending
on the uncertainties on each data point. These classes and the assumed
uncertainties are summarized in the following. \\

\noindent
In all three cases, the uncertainties for each data point (or bin
content) are assumed to be independent of each other. I.e., in the
case of histograms bin-by-bin migration is not included. The overall
conditional probability is a product of the individual probabilities
for the expectation value given the $y$-value (or bin content). \\

\noindent
An uncertainty band is calculated for each fit. During the
marginalization, each point in parameter space is sampled with a
frequency proportional to the posterior pdf at this point (if the
Markov chain has converged). The uncertainty band is obtained by
evaluating the fit function, $y(x)$, for each $x$ at each point in
parameter space. The values are histogrammed in
$x$--$y(x)$--space. Each slice of $x$ is normalized to unity and
interpreted as probability density for $y$ given $x$. The~0.16 and
0.84~quantiles are then interpreted as the uncertainty on $y$ at that
particular $x$. The uncertainty band can be returned from a model
using
%
\begin{verbatim}
TGraph * BCModel::GetErrorBandGraph(double level1, double level2) ,
\end{verbatim}
%
where the levels correspond to the quantiles of the distribution
$p(y(x))$ (default: 0.16 and 0.84). \\

\noindent
In all three cases, the fast methods for evaluating the $p$-value are
implemented. The $p$-value is evaluated automatically and returned
together with a summary.

% --------------------------------------------------------
\subsubsection{The Gaussian case}
\label{BCGraphFitter}

The class \verb|BCGraphFitter| allows to fit a \Root\ function
(\verb|TF1|) to a \Root\ graph (\verb|TGraphErrors|). The
uncertainties on $y$ at a given $x$, defined by the uncertainties of
the \verb|TGraphErrors|, are assumed to be Gaussian, i.e., the
uncertainty on $y$ corresponds to the width, $\sigma$, of the
Gaussian. The uncertainties on $x$ are not taken into account.  An
example for this fitter can be found in
\verb|examples/basic/graphFitter|.


% --------------------------------------------------------
\subsubsection{The Poissonian case}

The class \verb|BCHistogramFitter| allows to fit a \Root\ function
(\verb|TF1|) to a \Root\ histogram (\verb|TH1D|). The uncertainty on
the expectation value in each bin is assumed to be Poissonian, and
thus non-symmetric around the number of entries in this bin.  An
example for this fitter can be found in
\verb|examples/basic/histogramFitter|.


% --------------------------------------------------------
\subsubsection{The Binomial case}

The class \verb|BCEfficiencyFitter| allows to fit a \Root\ function
(\verb|TF1|) to the ratio of two \Root\ histograms (\verb|TH1D|). The
uncertainty on the expectation value in each bin is assumed to be
Binomial, and thus non-symmetric around the ratio of entries in this
bin. The ratio is assumed to be between 0 and 1, i.e., one histogram
contains a subset of the other.  An example for this fitter can be
found in \verb|examples/basic/efficiencyFitter|.

\enlargethispage{1cm}

\subsection{A model for template fitting}

A model for template fitting, \verb|BCTemplateFitter|, is provided
with BAT. A description of the method can be downloaded on the web
page. Three working examples are provided with the current release in
\verb|examples/advanced/templatefitter|.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% output
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\clearpage
\pagebreak

\section{Output}
\label{section:output}

\subsection{Log file}
\label{subsection:logfile}

The class \verb|BCLog| is used to write out information during the
runtime of the program. The output is written to screen and to a log
file. The minimum level of detail can be set independently for both
via
%
\begin{verbatim}
void BCLog::SetMinimumLogLevelFile(BCLog::LogLevel loglevel) ,
void BCLog::SetMinimumLogLevelScreen(BCLog::LogLevel loglevel) ,
\end{verbatim}
%
\noindent
where the level is one of the following
%
\begin{itemize}
\item \verb|debug|: Lowest level of information.
\item \verb|detail|: Details of functions, such as the status of the
  Markov chains, etc.
\item \verb|summary|: Results, such as best-fit values, normalization, etc.
\item \verb|warning|: Warning messages
\item \verb|nothing|: Nothing is written out.
\end{itemize}

A log file has to be opened in the beginning of the main file using
%
\begin{verbatim}
void BCLog::OpenLog() .
\end{verbatim}

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Summary information}

A summary of the MCMC run can be written to file or printed to the
screen using
%
\begin{verbatim}
BCModel::PrintSummary();
BCModel::PrintSummary(const char * file);
\end{verbatim}

The summary contains information about the convergence status, the
models, their parameters and respective ranges as well as information
about the marginalization (e.g., mean and rms, median and central 68\%
interval, and the smallest interval containing 68\% probability). The
results of the global maximization of the posterior probability is
also summarized.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Histograms}

Histograms of the marginalized distributions can be written to and
.eps file with the function
%
\begin{verbatim}
void PrintAllMarginalized(const char * file, int hdiv=1, int ndiv=1) ,
\end{verbatim}
%
\noindent
where \verb|file| is the filename and \verb|hdiv| and \verb|ndiv|
define the number of divisions in the plots. Alternatively, the
histograms can be obtained from the model (see
section~\ref{subsubsection:marginalization}) and then plotted, printed
or stored in a \Root\ file.

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{The output class}
\label{section:outputclass}

The results of an analysis can be stored in a \Root\ file using the
output class \verb|BCModelOutput|. This class is assigned a model
class and a file. It contains a \Root\ tree which stores the most
important information of the analysis outcome, such as the global
mode, the marginalized mode, means, limits, etc. The constructors are
%
\begin{verbatim}
BCModelOutput()
BCModelOutput(BCModel * model, const char * filename) .
\end{verbatim}
%
The model and filename can be set after construction using
%
\begin{verbatim}
BCModelOutput::SetModel(BCModel * model)
BCModelOutput::SetFile(const char * filename) .
\end{verbatim}
%
The marginalized distributions can also be stored in the output file
using
%
\begin{verbatim}
BCModelOutput::WriteMarginalizedDistributions() .
\end{verbatim}

The single points of the Markov Chain(s) can also be stored in the
output file together with the posterior probability at these
points. This can be done by setting a flag before the Markov Chain is
run:
%
\begin{verbatim}
BCModelOutput::WriteMarkovChain(bool flag = true) .
\end{verbatim}
%
Please note that the file size can be large in case you chose this
options. Each chain is stored as a \Root\ tree. This option allows for
offline diagnostics of the chains. The variables stored are: 

\begin{itemize}
\item fPhase: describes the phase of the running (1: pre-run, 2: main run),
\item fCycle: described the cycle of the chain in the pre-run,
\item fIteration: the current iteration number,
\item fNParameters: the number of parameters,
\item fLogLikelihood: the log of the posterior probability,
\item fParameter{\it i}: the parameter value of the {\it i}th parameter.
\end{itemize}

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% settings
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\section{Settings, options and special functions}
\label{section:settings}

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Markov Chain settings and options}
\label{section:settings:MCMC}

The most important options for the Markov Chains are listed here. For
further reference see the reference guide:
%
\begin{itemize}
\item \verb|BCModel::SetNChains(int n)| Sets the number of chains
  which are ran in parallel (default: 5).
\item \verb|BCModel::MCMCSetNIterationsMax(int n)| Sets the maximum
  number of iterations of the pre-run (default: 1,000,000).
\item \verb|BCModel::MCMCSetNIterationsRun(int n)| Sets the number of
  iterations of the analysis run (default: 100,000).
\item \verb|BCModel::MCMCSetNIterationsUpdate(int n)| Sets the number
  of iterations (default: 1,000) after which the chains are updated in
  the pre-run (e.g., for the calculation of the efficiency and
  convergence tests).
\item \verb|BCEngine::MCMCSetFlagOrderParameters(bool flag)|. Decides
  if all parameters should be varied one after each other (true) or
  all at the same time (default: true).
\item \verb|BCModel::MCMCSetFlagInitialPosition(int flag)| Decides how
  to chose the initial positions (0: center of the parameter
  boundaries, 1: random positions (default), 2: user defined
  positions).
\item \verb|BCModel::MCMCSetFlagFillHistograms(int index, bool flag)| and \\
  \verb|BCModel::MCMCSetFlagFillHistograms(bool flag)|. Set flag to fill the marginalized distribution for a single or all parameters. Not filling the distributions might increase the speed of MCMC run.
\item \verb|BCModel::MCMCSetInitialPositions(std::vector<double> x0s)|
  and \\
  \verb|MCMCSetInitialPositions(std::vector< std::vector<double> > x0s)|
  Set the initial positions of all parameters in all chains.
\item \verb|BCModel::MCMCSetMinimumEfficiency(double efficiency)| and \\
  \verb|MCMCSetMaximumEfficiency(double efficiency)|. Set the minimum
  (default: 15\%) and maximum (default: 50\%) efficiency of the Markov
  Chains. The efficiency found in the pre-run has to be within these
  limits otherwise the pre-run continues.
\item \verb|BCModel::MCMCSetRValueCriterion(double r)| Set the
  $r$-value criterion for convergence of a set of chains (default:
  0.1).
\item \verb|BCModel::WriteMarkovChain(bool flag)|. Set a flag to
 write the Markov Chain into a ROOT file. See
 section~\ref{section:outputclass} on how to handle output in BAT.
\item
  \verb|BCModel::MCMCSetPrecision(BCEngineMCMC::Precision precision)|. Set
  predefined values for running the algorithm with different
  precision. Possible varguments are \linebreak \verb|BCEngineMCMC::kLow| (for
  quick runs), \verb|BCEngineMCMC::kMedium| (for ``normal'' running),
  \linebreak \verb|BCEngineMCMC::kHigh| (for publications).
\end{itemize}

\paragraph{Proposal function}

The proposal function is set to a Breit-Wigner function per
default. The width of the Breit-Wigner is adjusted during the pre-run
to match the required efficiency of the sampling. The user can
overload the method
%
\begin{verbatim}
void BCEngineMCMC::MCMCTrialFunction(int chain, std::vector <double> &x)
void BCEngineMCMC::MCMCTrialFunctionSingle(int ichain,
                                           int iparameter,
                                           std::vector <double> &x)
\end{verbatim}

The first method is used in the case of unordered sampling, the second
one for ordered sampling. The vector $\verb|x|$ is filled with a
random number preferably in the range of 0~to~1. The numbers will be
scaled to the valid parameter range. An example for changing the trial
function can be found in \verb|examples/expert/TrialFunction|.\\

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

\subsection{Setting and options for Simulated Annealing}
\label{section:settings:SA}

The most important options for the implemented Simulated Annealing
algorithm are listed here. For further reference see the reference
guide:
%
\begin{itemize}
\item \verb|BCModel::SetSASchedule(BCModel::BCSASchedule)|. Set the
  annealing schedule. This could be \verb|BCModel::kSACauchy|,
  \verb|BCModel::kSABoltzmann|, \verb|BCModel::kSACustom|.
\item \verb|BCModel::SetSAT0(double T0)|. Set the starting
  temperature.
\item \verb|BCModel::SetSATmin(double Tmin)|. Set the threshold
  temperature.
\item \verb|BCModel::SetFlagWriteSAToFile(bool flag)|. Set a flag to
 write the individual steps of the simulated annealing into a ROOT
 file. See section~\ref{section:outputclass} on how to handle output in
 BAT.
\end{itemize}

% --------------------------------------------------------
% >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
% --------------------------------------------------------

%\subsection{Special functions}

% --------------------------------------------------------
% Technical tools
% --------------------------------------------------------
%\section{Technical tools}
%\label{section:tools}

%{\it Save all this for a later version of the manual.}

%\subsection{Optimization}

%\subsection{Markov Chain Monte Carlo}

%\subsection{Integration}

% --------------------------------------------------------
% More features
% --------------------------------------------------------
%\section{More features}
%\label{section:features}

%{\it Save all this for a later version of the manual.}

%\subsection{Normalization}

%\subsection{Model comparison}

%\subsection{Fitting}

%\subsection{Single event analysis}

%\subsection{User defined data interface}

% --------------------------------------------------------
% bibliography
% --------------------------------------------------------

\addcontentsline{toc}{section}{Bibliography}

\begin{thebibliography}{99}
\bibitem{Caldwell:2008fw}
  A.~Caldwell, D.~Kollar and K.~Kroeninger, ``BAT - The Bayesian
  Analysis Toolkit,'' \textit{Comp.\ Phys.\ Comm.}\ {\bf 180} (2009) 2197-2209
  [arXiv:0808.2552]
  \url{http://www.mppmu.mpg.de/bat/}
%
\bibitem{ROOTweb}
  \url{http://root.cern.ch/}
%
\bibitem{CUBA}
  T.~Hahn, ``CUBA: A library for multidimensional numerical
  integration,'' \textit{Comp.\ Phys.\ Comm.}\ {\bf 168} (2005) 78
  [arXiv:hep-ph/0404043].
%
\bibitem{CUBAweb}
  \url{http://www.feynarts.de/cuba/}

\bibitem{PDGstatistics}
Particle Data Group, Mathematical Tools or Statistics, Monte Carlo, Group Theory, Physics Letters B, Volume 667, Issues 1-5, Review of Particle Physics, 11 September 2008, Pages 316-339, ISSN 0370-2693, DOI: 10.1016/j.physletb.2008.07.030.
(http://www.sciencedirect.com/science/article/B6TVN-4T4VKPY-G/2/32a7641753a1a6d41124d1992263243a)

\bibitem{Johnson_pValue}
Johnson, V.E. A Bayesian chi2 Test for Goodness-of-Fit. The Annals of Statistics 32, 2361-2384(2004).

\end{thebibliography}

% --------------------------------------------------------

\end{document}


