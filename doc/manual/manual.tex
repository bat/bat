\documentclass[11pt, a4paper]{article}

\usepackage{epsfig}

\setlength{\oddsidemargin}{0cm}
\setlength{\evensidemargin}{0cm}
\setlength{\topmargin}{-1cm}
\setlength{\textheight}{23cm}
\setlength{\textwidth}{16cm}

\pagestyle{headings}

\newcommand{\BAT}{{\sc BAT}}

%--------------------------------------------------------

\begin{document}

% --------------------------------------------------------
% title
% --------------------------------------------------------

\thispagestyle{empty} 

\begin{figure}
\leftline{\includegraphics[scale=0.25]{bat.eps} 
\hspace{9.0cm} 
version 0.1} 
\end{figure} 

\title{\BAT\ - A {\sc Bayesian Analysis Toolkit}} 

\author{A.~Caldwell, D.~Kollar, K.~Kr\"oninger} 

\maketitle

\begin{abstract} 
Abstract. 
\end{abstract} 

\pagebreak 

% --------------------------------------------------------
% table of contents 
% --------------------------------------------------------

\tableofcontents

\pagebreak 

% --------------------------------------------------------
% introduction
% --------------------------------------------------------

\section{Introduction}

\subsection{Analysis paradigm} 

Describe the basic philosophy behind the type of data analysis which
we perform. This is more general than just the Bayesian formula. 

\subsection{Bayesian inference} 

\begin{equation}
p(A|B) = \frac{p(B|A) \cdot p_{0}(A)}{\int p(B|A) \cdot p_{0}(A) \, \mathrm{d}A }
\label{eqn:BayesTheorem}
\end{equation}

\subsection{Probability density function} 

We should give an introduction to how the output can be used, such as
defining the error band on our best fit curve, defining probability
intervals, propagating the probability density information to future
experiments, etc

\subsection{Goodness-of-fit} 

Lay the conceptual foundation. 

\subsection{Example uses of Bayesis Inference} 
\label{subsection:exampleuses} 

Describe in general terms how a problem is formulated. Some examples:

\begin{itemize}
\item Structure functions. 
%
\item Neutrinoless double beta-decay. 
% 
\item Cosmological models.  
\end{itemize}

\subsection{Requirements} 

The types of information the user will have to provide (bounds on
parameters, starting values, step sizes) plus the choices the user has
for output formats, types of outputs, etc.
Maybe define a model here. 

% --------------------------------------------------------
% installation 
% --------------------------------------------------------

\section{Installation} 

How to install BAT on your computer. Requirements, e.g. ROOT. 

% --------------------------------------------------------
% analysis chain
% --------------------------------------------------------

\section{Analysis chain}

The following section describes how to run the BAT software. The
strategy is the following: one or several classes are generated which
describe mathematical models. Parameters are defined within each model
and given limits. An interface to the model(s) reads in data from a
file. BAT can then be used to compare the probability for each model
and to estimate the parameters. This can be done with respect to the
overall probability density or the marginalized probability
densities. As a last step the ``goodness-of-fit'' can be estimated by
evaluating the posterior probability. 

% --------------------------------------------------------

\subsection{Getting started} 

The BAT software package provides a library with C++ classes which can
be implemented in any other program. In order to start a new project
several files need to be generated by the user: 
% 
\begin{itemize}
\item A makefile in which the link to the BAT-library is set. 
\item The include and source files of the model classes. 
\item A main file. 
\end{itemize} 

% --------------------------------------------------------

\subsection{Creating a model} 

In the following, the term {\it model} denotes a set of parameters, a
conditional probability for a set of data given the parameters, and
the prior probability for the set of parameters. A {\it model class}
is the implementation of such a model in terms of a C++ class. \\ 

\noindent 
A model class inherits from the class \verb|BCModel|. It has several
public methods which need to be overloaded by the user in order to
specify the mathematical expressions for each for the three
terms. These methods are
% 
\begin{itemize}
\item Constructor and destructor \\ 
 The constructor calls the method \verb|BCModel::DefineParameters()|.
% 
\item \verb|BCModel::DefineParameters()| \\
 This method is called at construction and contains the parameter
 definition. Parameters can either be defined as instances of
 \verb|BCParameter| and then added to the model via \\
 \verb|BCModel::AddParameter(BCParameter * parameter)|. \\ Or they can
 be defined implictly via \\ 
 \verb|BCModel::AddParameter(const char* name, double lowerlimit, double upperlimit)|.
% 
\item \verb|BCModel::LogLikelihood(std::vector <double> parameters)| \\ 
 This method calculates the logarithm of the conditional probability
 for the data given a set of parameter values. 
%
\item \verb|BCModel::LogAPrioriProbability(std::vector <double> parameters)| \\
 This method calculates the prior probability for a set of parameter
 values. 
\end{itemize} 

% --------------------------------------------------------

\subsection{Data format and handling} 

Data is stored in the form of data point which are combined to data
sets. Each data point is implemented as an instance of
\verb|BCDataPoint| and contains a set of double precision values. Data
sets are implemented as instances of \verb|BCDataSet|. Data points can
be generated explicitly by the user and than added to a data set
via. Alternatively, data sets can be read in from a file. \\ 

\noindent 
The values of a data point can be set either during construction or by
set methods. 
\begin{small}
\begin{verbatim}
BCDataPoint::BCDataPoint(vector<double> x) 
BCDataPoint::SetValue(int index, double value)  
BCDataPoint::SetValues(std::vector <double> values) 
\end{verbatim} 
\end{small} 

\noindent 
A data point is added to a data set via  
\begin{small}
\begin{verbatim}
BCDataSet::AddDataPoint(BCDataPoint* datapoint)
\end{verbatim} 
\end{small} 

\noindent 
Alternatively, data can be read in from a file using the methods 
\begin{small}
\begin{verbatim}
BCDataSet::ReadDataFromFileTree(char* filename, char* treename, const char* branchnames)
BCDataSet::ReadDataFromFileTxt(char* filename, int nvariables)
BCDataSet::ReadDataFromFileUser(char* filename, std::vector<int> options_int,
                                std::vector<double> options_double, const char* options_char)
\end{verbatim} 
\end{small} 

\noindent 
A data set is assigned to a model using a set method 
\begin{small} 
\begin{verbatim}
BCModel::SetDataSet(BCDataSet* dataset)
\end{verbatim} 
\end{small} 

% --------------------------------------------------------

\subsection{Handling more than one model: the model manager} 

In case more than one model is defined and all models use the same
data set a model manager can be defined. It is implemented as an
instance of the class \verb|BCModelManager|. \\ 

\noindent 
Models (and their prior probability) are added to the manager via
\begin{small}
\begin{verbatim}
BCModelManager::AddModel(BCModel * model, double probability) 
BCModelManager::AddModel(BCModel * model) 
\end{verbatim} 
\end{small} 

A common data set can be defined by 
\begin{small}
\begin{verbatim}
BCModelManager::SetDataSet(BCDataSet * dataset) 
\end{verbatim} 
\end{small} 

% --------------------------------------------------------

\subsection{Normalization and numerical integration} 

The denominator on the right hand side of Eqn.~\ref{eqn:BayesTheorem}
is an integral of the conditional probability times the prior
probability over all possible values of the parameters. This integral
has to be calculated to ensure the proper normalization of the
posterior probability. Since the analytical form of the integral is
generally not known this integral is solved numerically. Several
methods for numerical integration are implemented in the package. \\ 

\noindent 
The integration method can be chosen for each model by 
%
\begin{small}
\begin{verbatim}
BCIntegrate::SetIntegrationMethod(BCIntegrate::BCIntegrationType method), 
\end{verbatim} 
\end{small} 

\noindent
where \verb|BCIntegrationType| can be one of the following 
% 
\begin{itemize}
\item \verb|BCIntegrate::kIMonteCarlo| \\ 
 A sampled mean integration. 
\item \verb|BCIntegrate::kIImportance| \\ 
 A sampled mean integration with importance sampling. The method \\ 
 \verb|BCIntegrate::GetRandomPointImportance| needs to be overloaded.  
\item \verb|BCIntegrate::kIMetropolis| \\ 
 A sampled mean integration with importance sampling. The method \\ 
 \verb|BCIntegrate::GetRandomPointSamplingMetro| needs to be overloaded.  
\item \verb|BCIntegrate::kICuba| \\ 
 Interface to the cuba library~\cite{Hahn:2004fe}.
\end{itemize}

The time needed for the numerical integration can be constrained by
the maximum number of iterations and the relative precision aimed
at. These parameters can be set via 
%
\begin{small}
\begin{verbatim}
BCIntegrate::SetNIterationsMax(int niterations)
BCIntegrate::SetRelativePrecision(double relprecision) 
\end{verbatim} 
\end{small} 

% --------------------------------------------------------

\subsection{Hypothesis testing and model comparison} 

In case $N$ models are compared the normalization of the posterior
probability is important. Each model is assigned a prior probability
in the model manager. The posterior probability for a model given the
data is simply
%
\begin{equation}
p(\mathrm{Model \#1}|\mathrm{data}) = \frac{N_{1} \cdot p_{0}(\mathrm{Model \#1})}{\sum_{i = 1}^{N} N_{i} \cdot p_{0}(\mathrm{Model \#}i)} \, , 
\end{equation}
%
where $N_{i}$ is the normalization of the $i$th model posterior
probability (i.e. the denominator of the right hand side of
Eqn.~\ref{eqn:BayesTheorem}) and $p_{0}(\mathrm{Model \#}i)$ is the
prior probability for the $i$th model. 

% --------------------------------------------------------

\subsection{Parameter estimate and marginalization} 

If only a single parameter is to be estimated, the posterior
probability can be marginalized with respect to this parameter. From a
technical point of view it is most efficient to marginalize with
respect to all parameters simultaneously. This can be done by calling
the method
%
\begin{small}
\begin{verbatim}
BCModel::MarginalizeAll() 
\end{verbatim} 
\end{small} 

\noindent 
The marginalization can also be done for a one or two parameters via 
%
\begin{small}
\begin{verbatim}
BCModel::MarginalizeProbability(BCParameter* parameter)
BCModel::MarginalizeProbability(char* name) 
BCModel::MarginalizeProbability(BCParameter * parameter1, BCParameter * parameter2);
BCModel::MarginalizeProbability(char * name1, char * name2)
\end{verbatim} 
\end{small} 

\noindent 
Different methods are implemented to perform the actual
marginalization and can be set via
%
\begin{small}
\begin{verbatim}
BCIntegrate::SetMarginalizationMethod(BCIntegrate::BCMarginalizationType method)
\end{verbatim} 
\end{small} 

\noindent
where \verb|BCMarginalizationType| can be one of the following 
% 
\begin{itemize}
\item \verb|BCIntegrate::kMMonteCarlo| \\ 
 Uncorrelated sampling of the probability density. 
\item \verb|BCIntegrate::kMMetropolis| \\ 
 Correlated sampling using Markov chains. 
\end{itemize} 

\noindent 
Instances of the ROOT-based histogram classes \verb|BCH1D| and
\verb|BCH2D| are filled during the marginalization process and can be
returned via 
%
\begin{small}
\begin{verbatim}
BCModel::GetMarginalized(BCParameter * parameter) 
BCModel::GetMarginalized(char * name) 
BCModel::GetMarginalized(BCParameter * parameter1, BCParameter * parameter2) 
BCModel::GetMarginalized(char * name1, char * name2) 
\end{verbatim} 
\end{small} 

\noindent 
The histograms can be printed to an eps or ps file via 

\begin{small}
\begin{verbatim}
BCH1D::Print(char * filename, int options=0, double ovalue=0.)
\end{verbatim} 
\end{small} 

% --------------------------------------------------------

\subsection{Posterior probability check: a goodness-of-fit test} 

In case parameters are estimated for a certrain model and data set,
$D$, a test can be performed to judge the plausibility of the obtained
values. This ``goodness--of-fit'' test is based on a set of fake data
sets, $\{ \tilde{D} \}$, generated under the assumption of the
parameters obtained, $\lambda^{*}$. A frequency distribution $f$ of
the obtained conditional probability $k=p(\tilde{D}|\lambda^{*})$ is
calculated and interpreted as probability density. The $p$-value is
defined as the probability to find a conditional probability
$p(\tilde{D}|\lambda^{*})$ equal or larger than for the original data
set, $k_{0}=p(D|\lambda^{*})$, i.e.
%
\begin{equation}
p = \frac{1}{n} \int_{k_{0}=p(D|\lambda^{*})}^{1} f(k) \, \mathrm{d}k 
\end{equation} 

\noindent 
In the moment it is assumed that the user provides data sets with the
generated under the assumption of the parameters estimated. A file
containing list of data set files has to be provided. The
goodness-of-fit test is done by calling 
%
\begin{small}
\begin{verbatim}
BCModel::GoodnessOfFitTest(const char * filenname, std::vector <double> parameters) 
\end{verbatim} 
\end{small}

\noindent 
The method returns a pointer to a \verb|BCH1D|. The frequency
distribution can be printed as for the case of parameter estimates. 

% --------------------------------------------------------
% technical tools 
% --------------------------------------------------------

\section{Technical tools} 
\label{section:tools} 

Describe how numerical integrations are performed, how optimization is
done, etc. It should be clear what parameters can be controlled by the
user and what they mean.

% --------------------------------------------------------
% examples
% --------------------------------------------------------

\section{Examples}

% --------------------------------------------------------

\subsection{Example 01: Straight line fit} 

% --------------------------------------------------------

\subsection{Example 02: Polynomial fitting} 

% --------------------------------------------------------

\subsection{Example 03: Spectral analysis} 

% --------------------------------------------------------

\subsection{Example 04: Efficiency calculation} 

% --------------------------------------------------------
% appendix  
% --------------------------------------------------------

\begin{appendix}

\section{Parameters} 

\end{appendix} 

% --------------------------------------------------------
% bibliography 
% --------------------------------------------------------

\addcontentsline{toc}{section}{Bibliography}
%
\begin{thebibliography}{99}
\bibitem{Hahn:2004fe}
  T.~Hahn, ``CUBA: A library for multidimensional numerical
  integration,'' Comput.\ Phys.\ Commun.\ {\bf 168} (2005) 78
  [arXiv:hep-ph/0404043].
\end{thebibliography}


\end{document} 


